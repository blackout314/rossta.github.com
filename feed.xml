<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>rossta.net</title>
  <subtitle>Ross Kaffenberger</subtitle>
  <id>https://rossta.net/</id>
  <link href="https://rossta.net/"/>
  <link href="https://rossta.net/feed.xml" rel="self"/>
  <updated>2016-05-02T20:00:00-04:00</updated>
  <author>
    <name>Ross Kaffenberger</name>
  </author>
  <entry>
    <title>Service Worker on Rails</title>
    <link rel="alternate" href="/blog/service-worker-on-rails.html"/>
    <id>/blog/service-worker-on-rails.html</id>
    <published>2016-05-02T20:00:00-04:00</published>
    <updated>2016-05-02T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;Have you heard about &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API"&gt;Service
Worker&lt;/a&gt;? I
believe this new JavaScript API has the potential to transform the way users
interact with the web and how web developers construct websites. Though still in
development, Service Worker is already &lt;a href="https://jakearchibald.github.io/isserviceworkerready/"&gt;landing in modern...&lt;/a&gt;&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Have you heard about &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API"&gt;Service
Worker&lt;/a&gt;? I
believe this new JavaScript API has the potential to transform the way users
interact with the web and how web developers construct websites. Though still in
development, Service Worker is already &lt;a href="https://jakearchibald.github.io/isserviceworkerready/"&gt;landing in modern
browsers&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So far, there hasn&amp;rsquo;t been a good story for adding Service Worker to Rails. Until
now!&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a new Ruby gem, &lt;a href="https://github.com/rossta/serviceworker-rails"&gt;&lt;code&gt;serviceworker-rails&lt;/code&gt;&lt;/a&gt;, to make it easier to integrate Service Worker with the Rails asset pipeline. To understand why Rails developers might want to use this, let&amp;rsquo;s take a step back.&lt;/p&gt;

&lt;h2&gt;A brief intro&lt;/h2&gt;

&lt;p&gt;In its plainest form, service workers are just JavaScript running in a separate thread outside the context of a web page, like any other &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API"&gt;web worker&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But, service workers are special; they can act as &lt;strong&gt;client-side proxies&lt;/strong&gt;. This means they can &lt;em&gt;hook into the request/response cycle&lt;/em&gt; on the user&amp;rsquo;s machine.&lt;/p&gt;

&lt;p&gt;Hooking in to the request/response cycle on the client-side means we can improve the user experience in ways that weren&amp;rsquo;t possible (or much more difficult) previously. We could render HTML from a local cache while waiting for a response from the network or we could display another friendly page altogether when the network is offline. With service workers, we&amp;rsquo;ll be able to pre-fetch and sync data in the background, push activity notifications to users and even let them know when new releases have been deployed.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been &lt;a href="/blog/adding-serviceworker-to-a-simple-website.html"&gt;playing with Service Worker&lt;/a&gt; a bit lately. Now that you&amp;rsquo;ve visited my site, your browser has cached the data for &lt;a href="/offline.html"&gt;my offline page&lt;/a&gt;, so if you lost your network connection, you&amp;rsquo;d at least see a friendly message instead of the dreaded Chrome dinosaur.&lt;/p&gt;

&lt;p&gt;Go ahead and take a look at the &lt;a href="https://github.com/rossta/rossta.github.com/blob/45b67d326bb1118c9e0743ae74e1a5ca570a5947/source/assets/javascripts/serviceworker.js"&gt;source code for the rossta.net service worker&lt;/a&gt; to see how I did it. I&amp;rsquo;m still learning about Service Worker - is it &lt;em&gt;really&lt;/em&gt; new after all - so I&amp;rsquo;m sure there&amp;rsquo;s lots of ways I could improve it!&lt;/p&gt;

&lt;h2&gt;Let&amp;rsquo;s talk Rails&lt;/h2&gt;

&lt;p&gt;Next I wondered how I&amp;rsquo;d add a Service Worker to a Rails application. I&amp;rsquo;d expect Rails developers would want to be able to develop and deploy their service workers like any other JavaScript assets using the Rails asset pipeline. Not so fast though.&lt;/p&gt;

&lt;p&gt;As it turns out, to use Service Workers on Rails, we want some, but not all, of the Rails asset pipeline.&lt;/p&gt;

&lt;p&gt;The Rails asset pipeline makes a number of assumptions about what&amp;rsquo;s best for deploying JavaScript, including asset digest fingerprints and long-lived cache headers - mostly to increase &amp;ldquo;cacheability&amp;rdquo;. Rails also assumes a single parent directory, &lt;code&gt;/public/assets&lt;/code&gt;, to make it easier to look up the file path for a given asset.&lt;/p&gt;

&lt;p&gt;Service worker assets must play by different rules. Consider these behaviors:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Service workers may only be active from within the scope from which they are
served. So if you try to register a service worker from a Rails asset pipeline
path, like &lt;code&gt;/assets/serviceworker-abcd1234.js&lt;/code&gt;, it will only be able to interact
with requests and responses within &lt;code&gt;/assets/&lt;/code&gt;&lt;em&gt;**&lt;/em&gt;. This is not what we want.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API#Download_install_and_activate"&gt;MDN states&lt;/a&gt; browsers check for updated service worker scripts in the background every 24 hours (possibly less). Rails developers wouldn&amp;rsquo;t be able to take advantage of this feature since the fingerprint strategy means assets at a given url are immutable. Beside fingerprintings, the &lt;code&gt;Cache-Control&lt;/code&gt; headers used for static files served from Rails also work against browser&amp;rsquo;s treatment of service workers.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;**&lt;/em&gt;&lt;a href="https://slightlyoff.github.io/ServiceWorker/spec/service_worker/#service-worker-allowed"&gt;There is an early proposal&lt;/a&gt; to use the &lt;code&gt;Service-Worker-Allowed&lt;/code&gt; header to change scopes.&lt;/p&gt;

&lt;h2&gt;What to do?&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://github.com/rails/sprockets/issues/44"&gt;For now&lt;/a&gt;, Rails developers need to work around best practices in the Rails asset pipeline to use service workers.&lt;/p&gt;

&lt;p&gt;One approach would be to just place service worker scripts in &lt;code&gt;/public&lt;/code&gt;. That
could work, but it could mean foregoing the asset pipeline altogether. We lose
bundling, transpilation, testing and other features we do want. You could use
the pipeline but would then need to add steps to the build process to copy
precompiled service workers to the correct paths. In this case, you may want toaugment your
web server configuration to change &lt;code&gt;Cache-Control&lt;/code&gt; headers for those selected service worker scripts - this may not be possible in certain environments.&lt;/p&gt;

&lt;p&gt;Given the constraints around scoping, you could create
special controller actions to mount service workers at arbitrary routes. Rails
also gives you the ability to set custom headers on controller actions so that&amp;rsquo;s
another benefit. From there, you either write your JavaScript in a template where you may lose the advantage of the asset pipeline or
expose the contents of a precompiled asset from within the controller.&lt;/p&gt;

&lt;p&gt;I like this last option up until the point where a standard Rails controller
adds a lot of overhead, e.g. parameter parsing, session and cookie management, CSRF
protection, that isn&amp;rsquo;t needed for serving static files. From there, you can drop
down to a &lt;code&gt;ActionController::Metal&lt;/code&gt; subclass and figure out which extensions to
pull in&amp;hellip; or put this in a Rack middleware!&lt;/p&gt;

&lt;h2&gt;Using serviceworker-rails&lt;/h2&gt;

&lt;p&gt;This is what I&amp;rsquo;ve done with &lt;a href="https://github.com/rossta/serviceworker-rails"&gt;&lt;code&gt;serviceworker-rails&lt;/code&gt;&lt;/a&gt;. It inserts a middleware into the Rails stack that acts as a separate router for service worker scripts. In development, you can edit and recompile your service workers on the fly as with any other asset in the pipeline. In production, the service worker endpoints map to the precompiled asset in &lt;code&gt;/public/assets&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once the gem is added to your &lt;code&gt;Gemfile&lt;/code&gt;, you can add a Rails initializer to set
up the service worker middleware router:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# config/initializers/serviceworker.rb
Rails.application.configure do
  config.serviceworker.routes.draw do
    match &amp;quot;/serviceworker.js&amp;quot; =&amp;gt; &amp;quot;path/to/precompiled/serviceworker&amp;quot;
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, the middleware sets the &lt;code&gt;Cache-Control&lt;/code&gt; header to avoid aggressive caching. It also gives you the ability to customize headers as desired.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;match &amp;quot;/serviceworker.js&amp;quot; =&amp;gt; &amp;quot;app/serviceworker&amp;quot;, headers: { &amp;quot;X-Custom-Header&amp;quot; =&amp;gt; &amp;quot;foobar&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use globbing or named parameters in the service worker paths to interpolate
asset names.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;match &amp;quot;/*segments/serviceworker.js&amp;quot; =&amp;gt; &amp;quot;%{segments}/serviceworker&amp;quot;
match &amp;quot;/project/:id/serviceworker.js&amp;quot; =&amp;gt; &amp;quot;project/%{id}/serviceworker&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check out the project &lt;a href="https://github.com/rossta/serviceworker-rails#serviceworkerrails"&gt;README&lt;/a&gt; for more info on how to set up and configure the middleware for your Rails app.&lt;/p&gt;

&lt;p&gt;Though the project is still young, you can see &lt;code&gt;serviceworker-rails&lt;/code&gt; in action in the &lt;a href="https://serviceworker-rails.herokuapp.com/"&gt;Service Workers on Rails Sandbox&lt;/a&gt;. Inspired by Mozilla&amp;rsquo;s &lt;a href="https://serviceworke.rs/"&gt;Service Workers Cookbook&lt;/a&gt;, it serves as good place to experiment with Service Workers on Rails in an open source setting. Try using the site in Chrome Canary with the &lt;a href="https://www.chromium.org/blink/serviceworker/service-worker-faq"&gt;advanced service worker debugging tools&lt;/a&gt; to play around. I&amp;rsquo;ve added just a few examples so far but am interested to explore further with various caching strategies, push notifications, and eventually background sync to name a few.&lt;/p&gt;

&lt;p&gt;What do you think of this approach?&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Interested in contributing? &lt;a href="https://github.com/rossta/serviceworker-rails"&gt;Fork the serviceworker-rails gem&lt;/a&gt; or the &lt;a href="https://github.com/rossta/serviceworker-rails-sandbox"&gt;Service Workers on Rails Sandbox&lt;/a&gt; to get started.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>How to specify local Ruby gems in your Gemfile</title>
    <link rel="alternate" href="/blog/how-to-specify-local-ruby-gems-in-your-gemfile.html"/>
    <id>/blog/how-to-specify-local-ruby-gems-in-your-gemfile.html</id>
    <published>2016-04-22T20:00:00-04:00</published>
    <updated>2016-04-22T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;Let’s say you’re building a Ruby app and your team has extracted one or more
gems referenced in your Gemfile, such as your custom Trello API client, &lt;a href="https://github.com/rossta/tacokit.rb"&gt;Tacokit.rb&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Gemfile
source "https://rubygems.org"

# lots of gems ...

gem "tacokit"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Maybe Trello...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Let&amp;rsquo;s say you&amp;rsquo;re building a Ruby app and your team has extracted one or more
gems referenced in your Gemfile, such as your custom Trello API client, &lt;a href="https://github.com/rossta/tacokit.rb"&gt;Tacokit.rb&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Gemfile
source &amp;quot;https://rubygems.org&amp;quot;

# lots of gems ...

gem &amp;quot;tacokit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Maybe Trello made some recent changes to their API that your current feature depends
on, so you need to update the &lt;code&gt;Tacokit&lt;/code&gt; gem as part of your work. You have a
local checkout of the &lt;code&gt;tacokit&lt;/code&gt; gem in another directory in your laptop.&lt;/p&gt;

&lt;p&gt;You add some code to the gem, but now you want to test the changes in your app. How do you do that?&lt;/p&gt;

&lt;p&gt;According to &lt;em&gt;&lt;a href="http://stackoverflow.com/questions/4487948/how-can-i-specify-a-local-gem-in-my-gemfile#answer-4488110"&gt;the most popular answer (and accepted) answer&lt;/a&gt;&lt;/em&gt; to the question, &lt;a href="http://stackoverflow.com/questions/4487948/how-can-i-specify-a-local-gem-in-my-gemfile"&gt;&amp;ldquo;How can I specify a local gem in my Gemfile?&amp;rdquo;&lt;/a&gt;, we should do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;gem &amp;quot;tacokit&amp;quot;, path: &amp;quot;/path/to/tacokit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s my take: &lt;strong&gt;avoid this recommendation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;especially if you work on a team and/or deploy this code to remote servers.&lt;/p&gt;

&lt;h2&gt;WAT&lt;/h2&gt;

&lt;p&gt;Technically, it does work. Run &lt;code&gt;$ bundle update&lt;/code&gt;, restart the app, and - boom! - our changes in
the local &lt;code&gt;tacokit&lt;/code&gt; checkout are showing up as expected.&lt;/p&gt;

&lt;p&gt;Then the trouble begins.&lt;/p&gt;

&lt;p&gt;We push our app changes and deploy to the staging server to test them out
in the shared environment and - wait a minute - the app won&amp;rsquo;t even start.&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle
The path `/Users/ross/does/not/exist` does not exist.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! We forgot to remove the &lt;code&gt;:path&lt;/code&gt; reference in the &lt;code&gt;Gemfile&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s fix that&amp;hellip; we remove the &lt;code&gt;:path&lt;/code&gt; reference, push, and redeploy. The app
restarts fine. But while testing the feature, we start getting 500 errors. This wasn&amp;rsquo;t happening locally.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;But it worked on my machine!&amp;rdquo; - &lt;em&gt;every developer ever&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Rails logs reveal we have a bunch of undefined method errors coming from calls to &lt;code&gt;Tacokit&lt;/code&gt;. That&amp;rsquo;s right, we forgot another key step in this workflow: pushing our local &lt;code&gt;Tacokit&lt;/code&gt; changes to the remote!&lt;/p&gt;

&lt;p&gt;OK, after we&amp;rsquo;ve done that and redeployed the app, we&amp;rsquo;re still getting 500 errors.&lt;/p&gt;

&lt;p&gt;D&amp;#39;oh! We were working on a &lt;em&gt;branch&lt;/em&gt; of &lt;code&gt;tacokit&lt;/code&gt; but we reference it in our app&amp;rsquo;s &lt;code&gt;Gemfile&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Taking a step back&lt;/h2&gt;

&lt;p&gt;Good thing we weren&amp;rsquo;t pushing that app feature to production. We would have been wise to run the tests on our CI server first where we would have seen the same errors (assuming we had the right tests&amp;hellip; and a CI server).&lt;/p&gt;

&lt;p&gt;Using the &lt;code&gt;:path&lt;/code&gt; often means pointing to a location that only exists on our local machine. Every time we want to develop against the local &lt;code&gt;tacokit&lt;/code&gt; gem, we have to remember to edit the &lt;code&gt;Gemfile&lt;/code&gt; to remove the option so we don&amp;rsquo;t screw up our teammates or break the build. We also can&amp;rsquo;t forget to point to correct branch.&lt;/p&gt;

&lt;p&gt;This workflow is no good because we&amp;rsquo;re human and humans tend to forget to do things.&lt;/p&gt;

&lt;h2&gt;&amp;ldquo;bundle config local&amp;rdquo; to the rescue&lt;/h2&gt;

&lt;p&gt;Buried deep in the Bundler docs is a better solution for &lt;a href="http://bundler.io/git.html#local"&gt;working with local git repo&lt;/a&gt;: the &lt;code&gt;bundle config local&lt;/code&gt; command. Instead of specifying the &lt;code&gt;:path&lt;/code&gt; option, we can run the following on command line:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle config local.tacokit /path/to/tacokit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we instruct Bundler to look in a local resource by modifying our local Bundler configuration. That&amp;rsquo;s the one that lives in
&lt;code&gt;.bundle/config&lt;/code&gt; outside of version control.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;No more editing shared code for local development settings.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can confirm the link with &lt;code&gt;bundle config&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle config
Settings are listed in order of priority. The top value will be used.
local.tacokit
Set for your local app (/Users/rossta/.bundle/config): &amp;quot;/Users/rossta/path/to/tacokit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can scope the configuration to a specific folder with the &lt;code&gt;--local&lt;/code&gt; flag:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle config --local local.tacokit /path/to/tacokit
$ bundle config
Settings are listed in order of priority. The top value will be used.
local.tacokit
Set for your local app (/Users/rossta/path/to/app/.bundle/config): &amp;quot;/Users/rossta/path/to/tacokit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To take advantage of this local override in the app, we have to specify the remote repo and branch in the &lt;code&gt;Gemfile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;gem &amp;quot;tacokit&amp;quot;, github: &amp;quot;rossta/tacokit&amp;quot;, branch: &amp;quot;master&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bundler will abort if the local gem branch doesn&amp;rsquo;t match the one in the &lt;code&gt;Gemfile&lt;/code&gt; and checks that the sha in Gemfile.lock exists in the local repository.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This way we ensure our Gemfile.lock contains a valid reference to our local gem.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We don&amp;rsquo;t get these assertions when using the &lt;code&gt;:path&lt;/code&gt; option.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s easy to remove the local config after we don&amp;rsquo;t need it:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bundle config --delete local.YOUR_GEM_NAME&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;Caveats&lt;/h2&gt;

&lt;p&gt;As with the &lt;code&gt;:path&lt;/code&gt; option, we still need to remember to push our
local gem changes to the remote repository when using &lt;code&gt;bundle config local&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I should also mention that a good use case for using &lt;code&gt;:path&lt;/code&gt; instead of &lt;code&gt;bundle
config local&lt;/code&gt; it when the local gem is in a subdirectory relative to your app,
like when using &lt;a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"&gt;git submodules&lt;/a&gt;.
I don&amp;rsquo;t often see this in practice, but there are valid reasons for doing so.
The main point here is that the Gemfile options work for all systems where the
repository is bundled.&lt;/p&gt;

&lt;p&gt;In general, I&amp;rsquo;d encourage using either approach sparingly for gems that your
team doesn&amp;rsquo;t own as it&amp;rsquo;s typically best to stick the official releases for
active repositories. In my experience, it&amp;rsquo;s most common to develop against local gems for
projects that your team &lt;em&gt;does&lt;/em&gt; own, so &lt;code&gt;bundle config local&lt;/code&gt; will ensure your
co-workers know where to look to verify code dependencies.&lt;/p&gt;

&lt;h2&gt;Don&amp;rsquo;t use :path, use bundle config local instead&lt;/h2&gt;

&lt;p&gt;Though convenient, using the &lt;code&gt;:path&lt;/code&gt; option in our &lt;code&gt;Gemfile&lt;/code&gt; to point to a local
gem elsewhere on our machine sets us up for three potential problems without automated prevention:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Committing a nonexistent lookup path on other machines&lt;/li&gt;
&lt;li&gt;Failing to point to the correct repository branch&lt;/li&gt;
&lt;li&gt;Failing to point to an existing git reference&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Forget the &lt;code&gt;:path&lt;/code&gt; option and you&amp;rsquo;ll never forget ^^this stuff^^ again.&lt;/p&gt;

&lt;p&gt;Just use this command:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;bundle config local.YOUR_GEM_NAME`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And don&amp;rsquo;t believe everything you read on StackOverflow.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Adding Service Worker to a simple website</title>
    <link rel="alternate" href="/blog/adding-serviceworker-to-a-simple-website.html"/>
    <id>/blog/adding-serviceworker-to-a-simple-website.html</id>
    <published>2016-04-19T20:00:00-04:00</published>
    <updated>2016-04-19T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;Service Worker is well-suited to enhance a simple website like this blog. The &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API"&gt;Service Worker API&lt;/a&gt; has been designed in such as a way that developers can pick and choose the features they want without reworking their sites or committing to a (or another...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Service Worker is well-suited to enhance a simple website like this blog. The &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API"&gt;Service Worker API&lt;/a&gt; has been designed in such as a way that developers can pick and choose the features they want without reworking their sites or committing to a (or another) JavaScript framework.&lt;/p&gt;

&lt;p&gt;I recently added a service worker to rossta.net. You can read
the &lt;a href="https://github.com/rossta/rossta.github.com/blob/efbb4d41697a64543f5d4870c9915e633dda962d/source/assets/javascripts/serviceworker.js"&gt;full source of my serviceworker.js implementation&lt;/a&gt; here.&lt;/p&gt;

&lt;h3&gt;Requirements&lt;/h3&gt;

&lt;p&gt;To get my first service worker running, I did the following:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HTTPS everywhere&lt;/strong&gt; I moved rossta.net to &lt;a href="https://en.wikipedia.org/wiki/HTTPS_Everywhere"&gt;&amp;ldquo;HTTPS everywhere&amp;rdquo;&lt;/a&gt; with &lt;a href="https://www.cloudflare.com/"&gt;Cloudflare&lt;/a&gt;. Service workers will only run on sites served over HTTPS (or &lt;code&gt;localhost&lt;/code&gt; for development). If you&amp;rsquo;re considering Cloudflare for SSL, &lt;a href="https://scotthelme.co.uk/tls-conundrum-and-leaving-cloudflare/"&gt;be aware of the drawbacks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Registration&lt;/strong&gt; Though the Service Worker runs in its own thread outside the context of a webpage, we need to initiate its use from the webpage we&amp;rsquo;re on. So when you hit a page on rossta.net, there&amp;rsquo;s a snippet of JavaScript that checks for browser support and registers a service worker script for the root scope of the website.&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// index.js
if(&amp;#39;serviceWorker&amp;#39; in navigator) {
  navigator.serviceWorker.register(&amp;#39;/serviceworker.js&amp;#39;, {
    scope: &amp;#39;/&amp;#39;
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Service Worker Script&lt;/strong&gt; The service worker script gets deployed to &lt;a href="https://rossta.net/serviceworker.js"&gt;https://rossta.net/serviceworker.js&lt;/a&gt; separately from
the concatenated, versioned JavaScript bundles used on the main site.&lt;/p&gt;

&lt;h3&gt;The script&lt;/h3&gt;

&lt;p&gt;For the code in my first service worker script, I followed the strategy outlined by Jeremy Keith&amp;rsquo;s excellent
&lt;a href="https://adactio.com/journal/9775"&gt;My first Service Worker&lt;/a&gt;. He also provided a
generalized version of his script in a &lt;a href="https://gist.github.com/adactio/fbaa3a5952774553f5e7"&gt;service worker gist&lt;/a&gt; that&amp;rsquo;s definitely worth a look.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a general summary of the Service Worker&amp;rsquo;s responsibilities at various stages in its life cycle:&lt;/p&gt;

&lt;p&gt;On &lt;code&gt;install&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Pre-cache&amp;rdquo; any desired resource, primarily for rendering in an offline context&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On &lt;code&gt;activate&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clean up old cache when activating an update to the Service Worker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On &lt;code&gt;fetch&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Render HTML from the network while adding it to the local cache for use when offline&lt;/li&gt;
&lt;li&gt;Render JavaScript and CSS assets immediately from cache while updating the cache from the network when possible&lt;/li&gt;
&lt;li&gt;Render an offline page when a visitor can&amp;rsquo;t connect to rossta.net&lt;/li&gt;
&lt;li&gt;Allow normal pass-through network request of non-GET and white-listed resources like Twitter embeds and analytics tracking&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Deployment my service worker&lt;/h3&gt;

&lt;p&gt;Below I describe how I deployed my service worker, but your mileage may vary depending on your own production needs. &lt;a href="https://rossta.net/blog/why-i-ditched-wordpress-for-github.html"&gt;As I&amp;rsquo;ve said before&lt;/a&gt;, this is a static site hosted on Github pages, &lt;a href="/blog/using-webpack-with-middleman.html"&gt;built with Webpack and Middleman&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Setting up Github pages to use Cloudflare was relatively straightforward and has been &lt;a href="https://www.benburwell.com/posts/configuring-cloudflare-universal-ssl/"&gt;well-documented&lt;/a&gt;. I also wanted to make sure &lt;code&gt;serviceworker.js&lt;/code&gt; is always served over HTTPS and that it would not be cached. Since I don&amp;rsquo;t have any control on Github pages over related concerns like redirects and response headers. However, with Cloudflare, I set up Page Rules on Cloudflare to mitigate this issue.&lt;/p&gt;

&lt;p&gt;To ensure content on rossta.net is always loaded over HTTPS, I added a redirect page rule:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/cloud-flare-page-rules-https-7d097ad2.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m using Webpack to create &lt;a href="https://github.com/rossta/rossta.github.com/blob/09131d3adeb161747fa0cfc624db3ae12ab211fd/webpack.config.js#L12"&gt;separate bundles&lt;/a&gt; and Middleman&amp;rsquo;s &lt;a href="https://middlemanapp.com/advanced/improving_cacheability/"&gt;&lt;code&gt;:asset_hash&lt;/code&gt; extension&lt;/a&gt; to add a digest to each file, similar to the &lt;a href="http://guides.rubyonrails.org/asset_pipeline.html#in-production"&gt;Rails asset pipeline production behavior&lt;/a&gt; to improve the cacheability of CSS and JavaScript assets on rossta.net.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t want either for serviceworker.js: it must be served separately from the main asset bundles and it should not be cached.&lt;/p&gt;

&lt;p&gt;Webpack supports &lt;a href="https://webpack.github.io/docs/configuration.html#multiple-configurations"&gt;multiple configurations&lt;/a&gt;, so I set up my &lt;a href="https://github.com/rossta/rossta.github.com/blob/09131d3adeb161747fa0cfc624db3ae12ab211fd/webpack.config.js#L80"&gt;&lt;code&gt;webpack.config.js&lt;/code&gt;&lt;/a&gt; to use ES2015 transpilation for &lt;code&gt;serviceworker.js&lt;/code&gt; but output to a different destination from the other concatenated script files.&lt;/p&gt;

&lt;p&gt;To make sure Cloudflare does not cache &lt;code&gt;serviceworker.js&lt;/code&gt;, as it would by default for the CDN, I instructed Cloudflare to bypass the cache.&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/cloud-flare-page-rules-serviceworker-9f251642.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;Github pages currently adds 10-minute &lt;code&gt;Expires&lt;/code&gt; and &lt;code&gt;Cache-Control&lt;/code&gt; headers to resource requests meaning browsers and proxies may choose to cache &lt;code&gt;serviceworker.js&lt;/code&gt; past an update I&amp;rsquo;ve just deployed. This is a tradeoff I&amp;rsquo;ll have to live with until I move rossta.net to another host.&lt;/p&gt;

&lt;h3&gt;Caching considerations&lt;/h3&gt;

&lt;p&gt;There are some key considerations regarding the browser cache when setting up your first service worker with
an approach like the one &lt;a href="https://adactio.com/journal/9775"&gt;Jeremy Keith&lt;/a&gt; outlines and that I&amp;rsquo;ve used here in
rossta.net. Jeff Posnick, maintainer of Google Chrome&amp;rsquo;s &lt;a href="https://github.com/GoogleChrome/sw-precache"&gt;sw-precache&lt;/a&gt;, highlights some of these points &lt;a href="https://remysharp.com/2016/03/22/the-copy--paste-guide-to-your-first-service-worker"&gt;in a recent comment&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Any of the following would be safe, though they each have certain drawbacks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Serving all of the local assets with browser caching disabled.&lt;/li&gt;
&lt;li&gt;Cache-busting the requests that are used to populate the SW cache, using the non-cache-busted URL as the SW cache key.&lt;/li&gt;
&lt;li&gt;Explicitly versioning all of your local assets using something like gulp-rev, and then using long-lived browser caching headers.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some drawbacks of each:&lt;/p&gt;

&lt;p&gt;Approach 1. Means that all requests, even those coming from browsers without SW support, will bypass the browser cache, and that&amp;rsquo;s can be a lot of wasteful traffic.&lt;/p&gt;

&lt;p&gt;Approach 2. Can mean some extra code that makes the simple copy and paste example look a bit more complicated.&lt;/p&gt;

&lt;p&gt;Approach 3. Is a good practice to follow in general, but there&amp;rsquo;s an extra build-time step that you need to introduce, and it only applies to subresources, not URLs used as navigation targets (you&amp;rsquo;d likely just have to serve those bypassing the browser cache completely).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Realize that the browser cache is separate from the local cache used by the
service worker. So, when caching resources in your service worker, you may need
to consider the &amp;ldquo;cache busting&amp;rdquo; strategy for both your service worker and the
browser and &lt;a href="https://github.com/GoogleChrome/css-triggers/issues/14"&gt;how users may be affected when pushing updates to the site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If browser cache is disabled, then you can happily use your service worker to
cache resources without conflict, albeit, without the obvious benefits of a browser cache.&lt;/p&gt;

&lt;p&gt;In other words, take a moment to consider how your assets may (or may not) be cached by
browsers before &lt;a href="https://remysharp.com/2016/03/22/the-copy--paste-guide-to-your-first-service-worker"&gt;copying and pasting your first service worker&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Onward&lt;/h3&gt;

&lt;p&gt;There&amp;rsquo;s a lot more that can be done with the Service Worker API, but this was a
good start to see some impressive perceived performance improvements, especially when
reloading pages with images and special fonts.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Using Webpack with Middleman</title>
    <link rel="alternate" href="/blog/using-webpack-with-middleman.html"/>
    <id>/blog/using-webpack-with-middleman.html</id>
    <published>2016-04-15T20:00:00-04:00</published>
    <updated>2016-04-15T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;I’ve &lt;a href="/blog/why-i-ditched-wordpress-for-github.html"&gt;hosted this site on Github Pages&lt;/a&gt; with the &lt;a href="https://middlemanapp.com/"&gt;Middleman static site framework&lt;/a&gt; for several years now. To keep up with the most recent release of the framework, I decided to upgrade the site to &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;Middleman version 4&lt;/a&gt;. There were some significant changes...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;I&amp;rsquo;ve &lt;a href="/blog/why-i-ditched-wordpress-for-github.html"&gt;hosted this site on Github Pages&lt;/a&gt; with the &lt;a href="https://middlemanapp.com/"&gt;Middleman static site framework&lt;/a&gt; for several years now. To keep up with the most recent release of the framework, I decided to upgrade the site to &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;Middleman version 4&lt;/a&gt;. There were some significant changes to the configuration options and helper methods, which are &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;well documented&lt;/a&gt; on the Middleman blog.&lt;/p&gt;

&lt;p&gt;By far the biggest change was the &lt;a href="https://middlemanapp.com/advanced/asset_pipeline/"&gt;removal of the Sprockets&lt;/a&gt; dependency for the asset pipeline. Sprockets was originally a big selling point for me when choosing Middleman years ago. As a Rails developer, I had a lot of familiarity with the Sprockets style directives for bundling JavaScript and CSS assets and could use the pipeline to transpile CoffeeScript and SCSS easily.&lt;/p&gt;

&lt;p&gt;Given the &amp;ldquo;explosion of front-end language and tooling&amp;rdquo; that has happened over the past few years though, Sprockets has fallen behind in terms of speed and flexibility, among other things. With so many tools like &lt;a href="http://gruntjs.com/"&gt;Grunt&lt;/a&gt;, &lt;a href="http://gulpjs.com/"&gt;Gulp&lt;/a&gt;, &lt;a href="https://webpack.github.io"&gt;Webpack&lt;/a&gt;, &lt;a href="http://browserify.org/"&gt;Browserify&lt;/a&gt;, &lt;a href="http://brunch.io/"&gt;Brunch&lt;/a&gt;, &lt;a href="http://broccolijs.com/"&gt;Brocolli&lt;/a&gt;&amp;mdash;to name a few&amp;mdash;it would be unfeasible to support custom integrations for everything. Instead, Middleman now employs the &lt;code&gt;external_pipeline&lt;/code&gt; feature which allows &amp;ldquo;subprocesses&amp;rdquo; to run alongside the development server or build process.&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;I surpise even myself sometimes. Middleman v4’s external pipeline feature is amazing. Integrated Webpack inside Middleman. Dev &amp;amp; build modes&lt;/p&gt;&amp;mdash; Thomas Reynolds (@tdreyno) &lt;a href="https://twitter.com/tdreyno/status/580115759768059904"&gt;March 23, 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;In this post, I&amp;rsquo;ll describe how I set up the external pipeline for Webpack. I&amp;rsquo;ll be showing some Webpack configuration snippets to illustrate a few points but you can see the &lt;a href="https://github.com/rossta/rossta.github.com/blob/cc94b759ed742d571b2470777a0164ac43db9c73/webpack.config.js"&gt;full Webpack config file&lt;/a&gt; for this site as of this writing as well.&lt;/p&gt;

&lt;h3&gt;Before the upgrade&lt;/h3&gt;

&lt;p&gt;Before I upgrading the Middleman version 4, I had been using built-in Sprockets integration to configure, import, and transpile assets in the rossta.net static build. This required some custom imports in my Middleman &lt;a href="https://github.com/rossta/rossta.github.com/blob/96444337b05e6a996b8a6f2b63f353194bc9eb4b/config.rb#L122"&gt;&lt;code&gt;config.rb&lt;/code&gt;&lt;/a&gt; to make &lt;a href="http://foundation.zurb.com/"&gt;Foundation&lt;/a&gt; CSS and JavaScript available to the Sprockets runtime.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# config.rb
compass_config do |config|
  # Require any additional compass plugins here.
  config.add_import_path &amp;quot;../bower_components/foundation/scss&amp;quot;

  # Set this to the root of your project when deployed:
  config.http_path = &amp;quot;/&amp;quot;
  config.css_dir = &amp;quot;stylesheets&amp;quot;
  config.sass_dir = &amp;quot;stylesheets&amp;quot;
  config.images_dir = &amp;quot;images&amp;quot;
  config.javascripts_dir = &amp;quot;javascripts&amp;quot;
end

after_configuration do
  @bower_config = JSON.parse(IO.read(&amp;quot;#{root}/.bowerrc&amp;quot;))
  sprockets.append_path File.join(root, @bower_config[&amp;quot;directory&amp;quot;])

  sprockets.import_asset &amp;quot;foundation/js/vendor/jquery.cookie.js&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This configuration made it possible to require assets in JavaScript with the
&amp;ldquo;magic&amp;rdquo; Sprocket require comments, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// 3rd party javascript
//= require foundation/js/vendor/jquery
//= require foundation/js/vendor/jquery.cookie
//= require foundation

// My custom javascript
//= require zen
//= require tracking
//= require onload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With Sprockets dropped in Middleman version 4, this approach would no longer be
possible so I had to rethink the build pipeline. I preferred to support multiple
bundles and also wanted to upgrade my custom JavaScript to ES2015 syntax. For
this, &lt;a href="https://webpack.github.io/"&gt;Webpack&lt;/a&gt; appeared to offer some nice advantages, though, many of the
build tools and systems mentioned earlier would also make good choices and fit
right into the new Middleman external pipeline feature.&lt;/p&gt;

&lt;h3&gt;Enabling the External Pipeline&lt;/h3&gt;

&lt;p&gt;First step was to upgrade Middleman and remove Sprockets-based gems and
configuration from &lt;code&gt;config.rb&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;gem &amp;quot;middleman&amp;quot;, &amp;quot;~&amp;gt; 4&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle update middleman
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also deleted my Bower configuration and dependencies in favor of switching to
&lt;code&gt;npm&lt;/code&gt; to manage third-party assets. To setup my npm assets:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm init
$ npm install --save-dev webpack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The external pipeline feature in Middleman provides a mechanism for the
middleman development server to manage processes that live outside the Ruby
runtime. For Webpack, this means telling Middleman how to trigger the &lt;a href="https://webpack.github.io/docs/tutorials/getting-started/#setup-compilation"&gt;Webpack
compilation command&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;config.rb&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;activate :external_pipeline,
         name: :webpack,
         command: build? ?
         &amp;quot;./node_modules/webpack/bin/webpack.js --bail -p&amp;quot; :
         &amp;quot;./node_modules/webpack/bin/webpack.js --watch -d --progress --color&amp;quot;,
         source: &amp;quot;.tmp/dist&amp;quot;,
         latency: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I copied this configuration directly from the &lt;a href="middleman/middleman-core/lib/middleman-core/extensions/external_pipeline.rb"&gt;Middleman guides source&lt;/a&gt; which I learned made the same change recently.&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Commit upgrading Middleman Guides from Asset Pipeline to Webpack: &lt;a href="https://t.co/uP4LH19SfJ"&gt;https://t.co/uP4LH19SfJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Thomas Reynolds (@tdreyno) &lt;a href="https://twitter.com/tdreyno/status/678711274516033536"&gt;December 20, 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;Specifying &lt;code&gt;activate :external_pipeline&lt;/code&gt; enables Middleman&amp;rsquo;s external pipeline
extension (&lt;a href="https://github.com/middleman/middleman/blob/6872e07d34ab037897e8466db634efb9b49b4af5/middleman-core/lib/middleman-core/extensions/external_pipeline.rb"&gt;source&lt;/a&gt;). The three required options are worth noting:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# middleman/middleman-core/lib/middleman-core/extensions/external_pipeline.rb
option :name, nil, &amp;#39;The name of the pipeline&amp;#39;, required: true
option :command, nil, &amp;#39;The command to initialize&amp;#39;, required: true
option :source, nil, &amp;#39;Path to merge into sitemap&amp;#39;, required: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key point to understand here is Middleman will expect the external pipeline to output the compiled files to a directory which you specify here as &lt;code&gt;:source&lt;/code&gt;. We arbitrarily chose &lt;code&gt;.tmp/dist&lt;/code&gt; but it doesn&amp;rsquo;t matter so long as you use a dedicated destination. We&amp;rsquo;ll need to configure webpack separately to send its output here.&lt;/p&gt;

&lt;p&gt;Middleman will trigger the &lt;code&gt;:command&lt;/code&gt; in a thread and buffer its output to the Middleman logger so you can see what&amp;rsquo;s going on all in a single output stream. We use the &lt;code&gt;build?&lt;/code&gt; flag to modify the &lt;code&gt;webpack&lt;/code&gt; command for builds (which will fail fast) and development, where we want to watch for file changes and reload automatically.&lt;/p&gt;

&lt;p&gt;An optional &lt;code&gt;:latency&lt;/code&gt; can be used to set the seconds of delay between changes and refreshes.&lt;/p&gt;

&lt;h3&gt;Setting up Webpack&lt;/h3&gt;

&lt;p&gt;Webpack as a dizzying array of plugins and configuration options. The bare minimum to get JavaScript working with Webpack and Middleman is to set an &lt;code&gt;entry&lt;/code&gt; option to declare the primary source file(s) entry point and where it should compile to as the &lt;code&gt;output&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// webpack.config.js
var webpack = require(&amp;#39;webpack&amp;#39;);

module.exports = {
  entry: {
    site: &amp;#39;./source/javascripts/site.js&amp;#39;
  },

  resolve: {
    root: __dirname + &amp;#39;/source/javascripts&amp;#39;,
  },

  output: {
    path: __dirname + &amp;#39;/.tmp/dist&amp;#39;,
    filename: &amp;#39;javascripts/[name].js&amp;#39;,
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is not a full Webpack tutorial, but it worth noting we can use Webpack to do:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Transpile from ES2015 syntax&lt;/strong&gt;. We can pull in Babel dependencies and desired presets from &lt;code&gt;npm&lt;/code&gt; and declare &lt;code&gt;loaders&lt;/code&gt; in Webpack config to customize the compilation stages. This meant I was able to rewrite much of my custom JavaScript from ES5 to ES2015 and replace Sprocket-style require comments with executable &lt;code&gt;import&lt;/code&gt; statements.&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm install --save-dev babel babel-loader babel-preset-es2015 babel-preset-stage-0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// webpack.config.js
module.exports = {
  // ...

  module: {
    loaders: [
      {
        test: /source\/assets\/javascripts\/.*\.js$/,
        exclude: /node_modules|\.tmp|vendor/,
        loader: &amp;#39;babel-loader&amp;#39;,
        query: {
          presets: [&amp;#39;es2015&amp;#39;, &amp;#39;stage-0&amp;#39;]
        },
      },
      // ...
    ],
  }

  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Declare global variables&lt;/strong&gt;. I rely on the jQuery &lt;code&gt;$&lt;/code&gt; sign in enough places that
I decided to configure Webpack to treat it as a global variable so it would be
available in each of my JavaScript source files without declaring a separate
&lt;code&gt;import&lt;/code&gt; everywhere. This is done with the &lt;code&gt;webpack.ProvidePlugin&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// webpack.config.js
module.exports = {
  // ...

  plugins: [
    // ...
    new webpack.ProvidePlugin({
      $: &amp;quot;jquery&amp;quot;,
      jQuery: &amp;quot;jquery&amp;quot;,
      &amp;quot;window.jQuery&amp;quot;: &amp;quot;jquery&amp;quot;
    }),
  ],

  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Transpile SCSS to CSS&lt;/strong&gt;. Though Middleman still provides an integration with
Compass, &lt;a href="https://benfrain.com/lightning-fast-sass-compiling-with-libsass-node-sass-and-grunt-sass/"&gt;word on the street&lt;/a&gt; is that Node tools like &lt;code&gt;node-sass&lt;/code&gt; out-perform the Ruby Compass implementation. With the node-sass and some additional Webpack dependencies, we can transpile SCSS with Webpack to a separate css bundle:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm install --save-dev node-sass sass-loader extract-text-webpack-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// webpack.config.js
var ExtractTextPlugin = require(&amp;#39;extract-text-webpack-plugin&amp;#39;);

module.exports = {
  // ...

  entry: {
    styles: &amp;#39;./source/assets/stylesheets/styles.scss&amp;#39;,
    // ...
  },

  module: {
    loaders: [
      // ...
      {
        test: /.*\.scss$/,
        loader: ExtractTextPlugin.extract(
          &amp;quot;style&amp;quot;,
          &amp;quot;css!sass?sourceMap&amp;amp;includePaths[]=&amp;quot; + __dirname + &amp;quot;/node_modules&amp;quot;
        )
      },
      // Load plain-ol&amp;#39; vanilla CSS
      { test: /\.css$/, loader: &amp;quot;style!css&amp;quot; },
    ],
  }
  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Enable feature flags&lt;/strong&gt;. &lt;a href="https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html"&gt;I love puts debugging&lt;/a&gt; so I&amp;rsquo;ve got quite a few log statements in my JavaScript code. I don&amp;rsquo;t really want these log statements in the production build of the website, so I can use Webpack to allow me to enable logging only in development:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// webpack.config.js
var definePlugin = new webpack.DefinePlugin({
  __DEVELOPMENT__: JSON.stringify(JSON.parse(process.env.BUILD_DEVELOPMENT || false)),
  __PRODUCTION__: JSON.stringify(JSON.parse(process.env.BUILD_PRODUCTION || false))
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tell Webpack to make the &lt;code&gt;__DEVELOPMENT__&lt;/code&gt; and &lt;code&gt;__PRODUCTION__&lt;/code&gt; variables
available based on the presence on the &lt;code&gt;BUILD_DEVELOPMENT&lt;/code&gt; and
&lt;code&gt;BUILD_PRODUCTION&lt;/code&gt; environment variables. I pass these variables to the webpack
commands I&amp;rsquo;m using in &lt;code&gt;config.rb&lt;/code&gt; for the build and development Middleman
contexts respectively:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;activate :external_pipeline,
         name: :webpack,
         command: build? ?
         &amp;quot;BUILD_PRODUCTION=1 ./node_modules/webpack/bin/webpack.js --bail -p&amp;quot; :
         &amp;quot;BUILD_DEVELOPMENT=1 ./node_modules/webpack/bin/webpack.js --watch -d --progress --color&amp;quot;,
         source: &amp;quot;.tmp/dist&amp;quot;,
         latency: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I can then take advantage of feature flags in my JavaScript:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;function log() {
  if (__DEVELOPMENT__) {
    console.log(...arguments);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My development experience is greatly enhanced with the auto-recompile feature of
webpack along with the &lt;code&gt;middleman-livereload&lt;/code&gt; extension. Though I haven&amp;rsquo;t tried
the &lt;code&gt;webpack-dev-server&lt;/code&gt; and &lt;a href="https://webpack.github.io/docs/hot-module-replacement-with-webpack.html"&gt;hot-reloading of Webpack modules&lt;/a&gt;, it seems possible to set this up to work with Middleman.&lt;/p&gt;

&lt;p&gt;You can go much further with Webpack of course. For more info, check out the &lt;a href="https://webpack.github.io/"&gt;Webpack guides&lt;/a&gt; and Pete Hunt&amp;rsquo;s &lt;a href="https://github.com/petehunt/webpack-howto"&gt;Webpack How-to&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Moving away from Sprockets&lt;/h3&gt;

&lt;p&gt;The Middleman team has taken a big risk in dropping support for the primary asset management solution for Rails developers, likely the primary maintainers of Middleman apps. I believe it was the right choice. As someone who has been through the upgrade process, I can confirm it was challenging, but I have seen how great the payoff can be.&lt;/p&gt;

&lt;p&gt;In my opinion, if the Rails community wishes to stay relevant in the coming years, it would be wise to adopt a similar strategy: to &amp;ldquo;future proof&amp;rdquo; the rapidly changing front-end environment, Rails should drop Sprockets and embrace the external pipeline like Middleman.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Ancient City Ruby Snake Case</title>
    <link rel="alternate" href="/blog/ancient-city-snake-case.html"/>
    <id>/blog/ancient-city-snake-case.html</id>
    <published>2016-04-11T20:00:00-04:00</published>
    <updated>2016-04-11T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;Last week &lt;a href="#"&gt;I spoke&lt;/a&gt; at &lt;a href="#"&gt;Ancient City Ruby Conference&lt;/a&gt; where the organizers encouraged people to participate in a Ruby programming challenge called &lt;a href="http://www.ancientcityruby.com/snake_case/"&gt;Snake Case&lt;/a&gt;. I benchmarked a number of different ways to solve the challenge in Ruby and present the results...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;Last week &lt;a href="#"&gt;I spoke&lt;/a&gt; at &lt;a href="#"&gt;Ancient City Ruby Conference&lt;/a&gt; where the organizers encouraged people to participate in a Ruby programming challenge called &lt;a href="http://www.ancientcityruby.com/snake_case/"&gt;Snake Case&lt;/a&gt;. I benchmarked a number of different ways to solve the challenge in Ruby and present the results here.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the challenge:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;THE ANCIENT CITY RUBY 2016 PROGRAMMING CHALLENGE&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ve just arrived in sunny St. Augustine, and find yourself amazed by the visionary civic planning that would result in the area in which you now stand: a street grid exactly 10 blocks square.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;re in the northwest corner of this 10 by 10 block area, and would like to take a scenic walk to the southeast corner, while only ever moving south or east.&lt;/p&gt;

&lt;p&gt;As you begin walking, you wonder to yourself, &amp;ldquo;how many different paths could I take from this northwest corner to the southeast corner?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;You quickly note that if the downtown area were only a 2 block by 2 block grid, there would be 6 distinct paths from one corner to the other:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/snake-case-blocks-20fdedd0.png" /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth nothing that the intent of the problem was to calculate the correct
number of &amp;ldquo;optimal&amp;rdquo; paths along the blocks, so a meandering path does not count.
Starting at the northwest corner of a 10x10 grid, there will be 20 moves in
any valid path: 10 moves south and 10 moves east.&lt;/p&gt;

&lt;h3&gt;Recursion&lt;/h3&gt;

&lt;p&gt;How about a recursive solution? Consider that for any location &lt;code&gt;h, w&lt;/code&gt; on the grid, there are either one or two incoming paths oriented in the south or west direction, one coming from neighbor &lt;code&gt;h-1, w&lt;/code&gt; and the other coming from neighbor &lt;code&gt;h, w-1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This means that the solution for the given location is the sum of two subproblems: the number of paths arriving at location &lt;code&gt;h-1, w&lt;/code&gt; plus the number of paths arriving at location &lt;code&gt;h, w-1&lt;/code&gt;. In pseudocode:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(h, w) = path_count(h-1, w) + path_count(h, w-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exception to this rule is if either &lt;code&gt;h&lt;/code&gt; or &lt;code&gt;w&lt;/code&gt; are on the &amp;ldquo;edges&amp;rdquo;, meaning the
value is 0. In this case, there&amp;rsquo;s only 1 path that can reach these locations.&lt;/p&gt;

&lt;p&gt;Now we have enough information to construct a recursive solution to the problem:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# recursive
def path_count(h, w)
  return 1 if h == 0 || w == 0

  path_count(h-1, w) + path_count(h, w-1)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The expected result for a 10x10 grid is &lt;code&gt;184,756&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(10, 10)
# =&amp;gt; 184756
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works!  Let&amp;rsquo;s consider some alternative approaches.&lt;/p&gt;

&lt;h3&gt;Binary and Binomial&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://rayhightower.com/"&gt;Ray Hightower&lt;/a&gt;, who also &lt;a href="http://rayhightower.com/blog/2016/04/08/ancient-city-ruby-2016/"&gt;spoke at ACR&lt;/a&gt;, recently published a nice writeup of a &lt;a href="http://rayhightower.com/blog/2016/04/11/comparing-ruby-c-and-go/"&gt;&amp;ldquo;brute force&amp;rdquo; solution in Ruby, C, and Go&lt;/a&gt;. Please check out his detailed explanation of both a mathematical and brute force solution in Ruby.&lt;/p&gt;

&lt;p&gt;The mathematics approach is a factorial: given a 10x10 grid, we want to
construct 20 moves where 10 moves are &amp;ldquo;south&amp;rdquo; and 10 moves are &amp;ldquo;east&amp;rdquo;. We could
represent this conceptually as a bit map, where the total number of bits is
20^2, or &lt;code&gt;(h+w)**2&lt;/code&gt; where &lt;code&gt;h&lt;/code&gt; is the height and &lt;code&gt;w&lt;/code&gt; is the width of the grid. It
turns out this can be represented as a &lt;a href="https://en.wikipedia.org/wiki/Binomial_coefficient"&gt;binomial coefficient&lt;/a&gt; often expressed as:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/binomial-coefficient-c44f945f.gif" /&gt;&lt;/p&gt;

&lt;p&gt;Ray provided a nice LaTex-formatted description of the mathematics involved. Translated into a general Ruby function, this can be expressed in factorials.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# factorial
def path_count(h, w)
  (h+w).downto(h+1).reduce(:*) / w.downto(1).reduce(:*)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function gives the correct solution for 10x10: &lt;code&gt;184,756&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(10, 10)
# =&amp;gt; 184756
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &amp;ldquo;brute-force&amp;rdquo; solution counts up all the &amp;ldquo;1&amp;rdquo; bits in all possible combination
of bits from 0 to 2^(h+w), or 2^20 in our case of a 10x10 grid.&lt;/p&gt;

&lt;p&gt;Expressed in a general Ruby function:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# brute force
def path_count(h, w)
  (0..(2**(h+w))).count { |x| x.to_s(2).chars.count(&amp;quot;1&amp;quot;) == n }
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The total number of bits to explore is equal to &lt;code&gt;2**(h+w)&lt;/code&gt;. We count how many of
those numbers, when expressed as binary with &lt;code&gt;x.to_s(2)&lt;/code&gt; have 10 &amp;ldquo;1&amp;rdquo; bits.&lt;/p&gt;

&lt;h3&gt;Iteration&lt;/h3&gt;

&lt;p&gt;The recursive solution asks us to solve the problem backwards in a way: given
the destination, figure out the solution by solving the problem for the nearest previous destinations and the ones that came before those and so on. What if we could &amp;ldquo;build up&amp;rdquo; to the solution instead? We can take an iterative approach in stead.&lt;/p&gt;

&lt;p&gt;Imagine each corner or &amp;ldquo;node&amp;rdquo; of the grid can be represented as the number of paths leading to it. For a 5x5 grid, there are 6 nodes and each would have a value of &lt;code&gt;1&lt;/code&gt;, since there is only one way to get to those nodes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1  # first row of a 5x5 grid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The second row gets interesting. Each node will be the sum of paths leading to
the nodes immediately north and west. So, the first node in the second row is
still just &lt;code&gt;1&lt;/code&gt; since no paths lie to the west and the value of the node
immediately to the north is &lt;code&gt;1&lt;/code&gt;. The second node in the second row gets a value
of &lt;code&gt;2&lt;/code&gt; since the node to the west is now &lt;code&gt;1&lt;/code&gt; and the node to the north is also &lt;code&gt;1&lt;/code&gt;. Continuing on, this gives a second row of &lt;code&gt;1 2 3 4 5 6&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1
1--2--3--4--5--6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The third row:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1
1--2--3--4--5--6
1--3--6--10-15-21
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And so on&amp;hellip; The number of paths for a given grid would simply be the value of
the last node in the last row. Let&amp;rsquo;s implement this in Ruby:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# iterative
def path_count(h, w)
  row = [1] * (w+1) # first row of &amp;quot;1s&amp;quot;

  h.times do
    row = row.reduce([]) { |acc, p| acc &amp;lt;&amp;lt; (p + acc.last.to_i)  }
  end

  row.last
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;reduce&lt;/code&gt; expression generates a row from the previous one and the values of
each previous member of the current row. The function returns the last member of
the last row.&lt;/p&gt;

&lt;p&gt;Since &lt;a href="/talks/ruby-enumerator.html"&gt;I gave a talk about Enumerator at Ancient City&lt;/a&gt; I decided it would only
be appropriate if I solved the Snake Case challenge using an &lt;code&gt;Enumerator&lt;/code&gt;. We
can extract an Enumerator from the iterative solution to represent a function that generates each row of the grid:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def grid(h, w)
  return to_enum(:grid, h, w) unless block_given?

  row = [1] * (w+1)
  yield row

  h.times do
    row = row.reduce([]) { |acc, p| acc &amp;lt;&amp;lt; (p + acc.last.to_i)  }
    yield row
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two key changes have been made. We&amp;rsquo;ve inserted &lt;code&gt;yield&lt;/code&gt; statements to allow the
caller to receive each row of the grid as it is generated. We also  &amp;ldquo;enumeratorize&amp;rdquo; our iterative function by converting the behavior of the function into an &lt;code&gt;Enumerator&lt;/code&gt; when no block is given in the first line.&lt;/p&gt;

&lt;p&gt;Calling &lt;code&gt;grid(10, 10)&lt;/code&gt; returns an &lt;code&gt;Enumerator&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;grid(10, 10)
# =&amp;gt; #&amp;lt;Enumerator: ...&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Calling &lt;code&gt;to_a&lt;/code&gt; on our &lt;code&gt;Enumerator&lt;/code&gt; creates each &amp;ldquo;node&amp;rdquo; value:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;grid(10, 10).to_a
# =&amp;gt; [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
# [1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66],
# [1, 4, 10, 20, 35, 56, 84, 120, 165, 220, 286],
# [1, 5, 15, 35, 70, 126, 210, 330, 495, 715, 1001],
# [1, 6, 21, 56, 126, 252, 462, 792, 1287, 2002, 3003],
# [1, 7, 28, 84, 210, 462, 924, 1716, 3003, 5005, 8008],
# [1, 8, 36, 120, 330, 792, 1716, 3432, 6435, 11440, 19448],
# [1, 9, 45, 165, 495, 1287, 3003, 6435, 12870, 24310, 43758],
# [1, 10, 55, 220, 715, 2002, 5005, 11440, 24310, 48620, 92378],
# [1, 11, 66, 286, 1001, 3003, 8008, 19448, 43758, 92378, 184756]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the last value of the last row is the correct answer to our path count
challenge.&lt;/p&gt;

&lt;p&gt;For our revised &lt;code&gt;path_count&lt;/code&gt; method, we simply want to retrieve the last member of the last row:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# enumeartive
def path_count(h, w)
  grid(h, w).drop(h-1).last.last
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that the nodes of this grid follow the pattern of Pascal&amp;rsquo;s
Triangle expanding from the northwest corner. Pascal&amp;rsquo;s Triangle is well suited for an Enumerator function as &lt;a href="/blog/pascals-triangle-with-rubys-enumerator.html"&gt;I&amp;rsquo;ve written about previously&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Tradeoffs&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ve described a number of ways to solve Snake Case and each comes with
tradeoffs.&lt;/p&gt;

&lt;p&gt;In terms of readability, I would personally place the solutions in the following
order from most to least readable:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Recursive&lt;/li&gt;
&lt;li&gt;Iterative&lt;/li&gt;
&lt;li&gt;Brute force&lt;/li&gt;
&lt;li&gt;Factorial&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At least for me, the recursive solution is the easiest to wrap my
head around and most readable result. It&amp;rsquo;s easy to see from the recursive implementation how the problem may be divided into smaller sub-problems. The others require some deeper visualization and/or mathematical understanding to &amp;ldquo;grok&amp;rdquo; I feel. The factorial expression seems farthest removed conceptually from the description of the problem. In other words, it&amp;rsquo;s most at odds with my intuition, but I&amp;rsquo;m also not a mathematician so am less inclined to think in those terms.&lt;/p&gt;

&lt;p&gt;How do they compare performance-wise? With &lt;code&gt;benchmark-ips&lt;/code&gt; we can compare the
iterations/second and share the results.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a file that defines each of the approaches we&amp;rsquo;ve described in separate
modules and benchmarks the performance for calculating the result for a 10x10
grid. (&lt;a href="https://github.com/rossta/loves-enumerable/blob/edbab0fcb2aeac65a7b34d9fa603b3aa58563b4f/code/snake_case.rb"&gt;Full source&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Running on my mid-2014 MacBook Pro with MRI ruby-2.3:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;quot;benchmark/ips&amp;quot;

Benchmark.ips do |x|
  x.report(&amp;quot;snake case factorial&amp;quot;) do
    SnakeCase::Factorial.path_count(10, 10)
  end

  x.report(&amp;quot;snake case brute force&amp;quot;) do
    SnakeCase::Bruteforce.path_count(10, 10)
  end

  x.report(&amp;quot;snake case recursive&amp;quot;) do
    SnakeCase::Recursive.path_count(10, 10)
  end

  x.report(&amp;quot;snake case iterative&amp;quot;) do
    SnakeCase::Iterative.path_count(10, 10)
  end

  x.report(&amp;quot;snake case enumerative&amp;quot;) do
    SnakeCase::Enumerative.path_count(10, 10)
  end

  x.compare!
end

# $ SHARE=1 ruby code/snake_case.rb
# Calculating -------------------------------------
# snake case factorial    34.658k i/100ms
# snake case brute force
#                          1.000  i/100ms
# snake case recursive     5.000  i/100ms
# snake case iterative     4.920k i/100ms
# snake case enumerative
#                          4.109k i/100ms
# -------------------------------------------------
# snake case factorial    456.100k (± 7.8%) i/s -      2.287M
# snake case brute force
#                           0.325  (± 0.0%) i/s -      2.000  in   6.161730s
# snake case recursive     50.084  (±10.0%) i/s -    250.000
# snake case iterative     52.616k (± 5.3%) i/s -    265.680k
# snake case enumerative
#                          42.875k (± 7.1%) i/s -    213.668k
#
# Comparison:
# snake case factorial:   456100.0 i/s
# snake case iterative:    52615.9 i/s - 8.67x slower
# snake case enumerative:    42874.6 i/s - 10.64x slower
# snake case recursive:       50.1 i/s - 9106.72x slower
# snake case brute force:        0.3 i/s - 1405090.92x slower
#
# Shared at: https://benchmark.fyi/f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The factorial solution is orders of magnitude faster than the others. The iterative (and relatively similar enumerative) examples are only about ~10x slower than the factorial version while the recursive solution is almost 10,000x slower. The brute force solution is over a million-times slower. Even though the standard deviation in some of the results was fairly large, the differences across strategies appear conclusive.&lt;/p&gt;

&lt;p&gt;The maintainer of &lt;code&gt;benchmark-ips&lt;/code&gt;, &lt;a href="https://twitter.com/evanphx"&gt;Evan Phoenix&lt;/a&gt;, added the ability to share benchmark results online. You can see &lt;a href="https://benchmark.fyi/f"&gt;the results for this test on benchmark.fyi&lt;/a&gt;. The &lt;a href="https://github.com/rossta/loves-enumerable/blob/edbab0fcb2aeac65a7b34d9fa603b3aa58563b4f/code/snake_case.rb"&gt;full source code is also on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;And the winner is&amp;hellip;&lt;/h3&gt;

&lt;p&gt;All of the above!&lt;/p&gt;

&lt;p&gt;This serves as a good illustration of how there&amp;rsquo;s often no single &amp;ldquo;best&amp;rdquo; way to
solve a problem with considering the circumstance. In a situation where
performance matters, the mathematical approach has a clear advantage, but
sacrifices readability. I might be inclined to choose the iterative or recursive
approach in situations where performance isn&amp;rsquo;t the key concern.&lt;/p&gt;

&lt;p&gt;Given my preference for &lt;a href="https://rossta.net/blog/series/enumerable.html"&gt;Enumerable&lt;/a&gt;, I personally love the enumerative approach, but, as &lt;a href="https://rossta.net/talks/ruby-enumerator.html"&gt;I discussed at Ancient City Ruby&lt;/a&gt;, I doubt most would agree.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Thread Pool - A Ruby Antihero</title>
    <link rel="alternate" href="/blog/a-ruby-antihero-thread-pool.html"/>
    <id>/blog/a-ruby-antihero-thread-pool.html</id>
    <published>2016-03-01T19:00:00-05:00</published>
    <updated>2016-03-01T19:00:00-05:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;One of the fundamental concepts in key Ruby libraries that embrace
concurrency is the &lt;a href="https://en.wikipedia.org/wiki/Thread_pool"&gt;thread pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can find examples of thread pool implementations in gems like
&lt;a href="https://github.com/puma/puma"&gt;puma&lt;/a&gt;,
&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;,
&lt;a href="https://github.com/celluloid/celluloid"&gt;celluloid&lt;/a&gt;,
&lt;a href="https://github.com/bruceadams/pmap"&gt;pmap&lt;/a&gt;,
&lt;a href="https://github.com/grosser/parallel/blob/6ebee4ff5c0933da241a182e366eee9227b49764/lib/parallel.rb#L66"&gt;parallel&lt;/a&gt;,
and &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A thread pool...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;One of the fundamental concepts in key Ruby libraries that embrace
concurrency is the &lt;a href="https://en.wikipedia.org/wiki/Thread_pool"&gt;thread pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can find examples of thread pool implementations in gems like
&lt;a href="https://github.com/puma/puma"&gt;puma&lt;/a&gt;,
&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;,
&lt;a href="https://github.com/celluloid/celluloid"&gt;celluloid&lt;/a&gt;,
&lt;a href="https://github.com/bruceadams/pmap"&gt;pmap&lt;/a&gt;,
&lt;a href="https://github.com/grosser/parallel/blob/6ebee4ff5c0933da241a182e366eee9227b49764/lib/parallel.rb#L66"&gt;parallel&lt;/a&gt;,
and &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A thread pool is an abstraction for re-using a limited number of threads to
performing concurrent work.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Thread pool - no relation" src="/assets/images/blog/threadpool-428287d8.png" /&gt;&lt;/p&gt;

&lt;p&gt;General usage of a thread pool might look something like the following, where the &lt;code&gt;:size&lt;/code&gt;
represents the maximum number of threads open at any given time.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = ThreadPool.new(size: 5)

10_000.times do
  pool.schedule { do_work }
end

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The calculation would be performed 10,000 times across five separate threads.&lt;/p&gt;

&lt;p&gt;To get a better understanding of how thread pools work, let&amp;rsquo;s implement a thread
pool in test-driven fashion.&lt;/p&gt;

&lt;aside class="callout panel"&gt;
&lt;p&gt;
  The code samples in this post are run on &lt;code&gt;rubinius-3.14&lt;/code&gt; to take advantage of
  parallel processing. As you may know, MRI&amp;rsquo;s
&lt;a href="http://www.jstorimer.com/blogs/workingwithcode/8085491-nobody-understands-the-gil"&gt;global interpreter lock&lt;/a&gt;
ensures only one code can execute Ruby code at any one time.
&lt;/p&gt;
&lt;/aside&gt;

&lt;h3&gt;Don&amp;rsquo;t be afraid&lt;/h3&gt;

&lt;p&gt;Before we dive in, let&amp;rsquo;s acknowledge that Rubyists, and most OO programmers in general,
are taught to fear multi-threaded concurrency.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;first rule&lt;/em&gt; of concurrency on the JRuby wiki, a Ruby implementation
designed to take advantage of native operating systems threads, is this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t do it, if you can avoid it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the purpose of this post, I&amp;rsquo;m going to assume the author means &amp;ldquo;in
production&amp;rdquo;. In the safety of your development environment, playing with
concurrency in Ruby can be a tremendous learning opportunity.&lt;/p&gt;

&lt;h3&gt;A simple thread pool&lt;/h3&gt;

&lt;p&gt;So we&amp;rsquo;ll implement a simple thread pool guided by tests. Our thread pool will use the
interface we described earlier while limiting the number of threads
used to carry out a set of concurrent &amp;ldquo;jobs&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = ThreadPool.new(size: 5)

pool.schedule { do_work }

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Basic usage&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ll start with a thread pool that doesn&amp;rsquo;t do any concurrent processing.
It will execute the block given to its &lt;code&gt;#schedule&lt;/code&gt; method
directly. Though we&amp;rsquo;ll add other tests later to exercise concurrency in the
implementation, this first test will assume the concurrency is already
implemented.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s our first test.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;minitest/autorun&amp;#39;
require &amp;#39;minitest/pride&amp;#39;
require_relative &amp;#39;./thread_pool&amp;#39;

class TestThreadPool &amp;lt; Minitest::Test
  def test_basic_usage
    pool_size = 5
    pool = ThreadPool.new(size: pool_size)

    mutex = Mutex.new

    iterations = pool_size * 3
    results = Array.new(iterations)

    iterations.times do |i|
      pool.schedule do
        mutex.synchronize do
          results[i] = i + 1
        end
      end
    end
    pool.shutdown

    assert_equal(1.upto(pool_size * 3).to_a, results)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break it down. To test the basic usage of a thread pool scheduler, we&amp;rsquo;ll pass in an array and
augment it with in the scheduled blocks. Because &lt;a href="http://www.jstorimer.com/pages/ruby-core-classes-arent-thread-safe"&gt;&lt;code&gt;Array&lt;/code&gt; is not thread safe&lt;/a&gt;,
we need to use a &lt;a href="http://ruby-doc.org/core-2.2.0/Mutex.html"&gt;&lt;code&gt;Mutex&lt;/code&gt;&lt;/a&gt; object to lock the pooled threads while adding items to the array.&lt;/p&gt;

&lt;p&gt;The key snippet is here:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool.schedule do
  mutex.synchronize do
    results[i] = i + 1
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The test asserts that the results match &lt;code&gt;1.upto(15)&lt;/code&gt; as an array.&lt;/p&gt;

&lt;p&gt;To make the tests pass:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
  end

  def schedule(*args, &amp;amp;block)
    block.call(args)
  end

  def shutdown
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ve just stubbed out the &lt;code&gt;#initialize&lt;/code&gt; and &lt;code&gt;#shutdown&lt;/code&gt; methods since
additional behavior isn&amp;rsquo;t needed to get the tests to pass.&lt;/p&gt;

&lt;p&gt;You can see the source for &lt;a href="https://github.com/rossta/loves-enumerable/commit/fcd81ec86ae3525d8f0a3acf914507e2962fb962"&gt;this changeset on Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Saving time&lt;/h3&gt;

&lt;p&gt;Our next test will demonstrate that we&amp;rsquo;re actually taking advantage of concurrency by
(crudely) measuring the time taken to process multiple jobs.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use a small test helper method to measure the number of
seconds elapsed during execution:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def time_taken
  now = Time.now.to_f
  yield
  Time.now.to_f - now
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our test will schedule 5 jobs that will each sleep for 1 second.
If the jobs executed serially, the total execution time would be at least 5
seconds. Running in parallel on Rubinius, we&amp;rsquo;d expect threaded-execution of 5 jobs
across 5 threads to take less time.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def test_time_taken
  pool_size = 5
  pool = ThreadPool.new(size: pool_size)
  elapsed = time_taken do
    pool_size.times do
      pool.schedule { sleep 1 }
    end
    pool.shutdown
  end
  assert_operator 4.5, :&amp;gt;, elapsed,
    &amp;#39;Elapsed time was too long: %.1f seconds&amp;#39; % elapsed
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This test fails with our first pass-through implementation of &lt;code&gt;ThreadPool&lt;/code&gt;. We
can make this test pass by wrapping each scheduled job in its own thread.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
    @pool = []
  end

  def schedule(*args, &amp;amp;block)
    @pool &amp;lt;&amp;lt; Thread.new { block.call(args) }
  end

  def shutdown
    @pool.map(&amp;amp;:join)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We push each of these threads onto an array, &lt;code&gt;@pool&lt;/code&gt;, which we can use to join
the threads during the &lt;code&gt;#shutdown&lt;/code&gt; method. The tests pass again.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/rossta/loves-enumerable/commit/1d1cbc808a536a449b8f6dab5b9d4e0cb037f99c"&gt;Source for this changeset&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Adding Pooling&lt;/h3&gt;

&lt;p&gt;While we&amp;rsquo;ve achieved concurrency, you may notice there&amp;rsquo;s (at least) one problem.&lt;/p&gt;

&lt;p&gt;Our current implementation will naively create a new thread for each scheduled
job. This may not be an issue for small, trivial use cases, but it can be easily
abused. Thread creation does not come for free; every OS has its limit.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll prove it with our next test in which we&amp;rsquo;ll schedule a large number of
jobs.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def test_pool_size_limit
  pool_size = 5
  pool = ThreadPool.new(size: pool_size)
  mutex = Mutex.new
  threads = Set.new

  100_000.times do
    pool.schedule do
      mutex.synchronize do
        threads &amp;lt;&amp;lt; Thread.current
      end
    end
  end
  pool.shutdown

  assert_equal(pool_size, threads.size)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running these tests on my mid-2014 MacBook Pro, I hit the resource limit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TestThreadPool#test_pool_size_limit:
ThreadError: can&amp;#39;t create Thread: Resource temporarily unavailable
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `initialize&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `new&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `block in test_pool_size_limit&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:52:in `times&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:52:in `test_pool_size_limit&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is now the whole point of our &lt;code&gt;ThreadPool&lt;/code&gt;, to limit the number of threads
in use. To implement this behavior, instead of executing the scheduled job in a
new thread, we&amp;rsquo;ll add them to a &lt;code&gt;Queue&lt;/code&gt;. We&amp;rsquo;ll separately create a
limited number of threads whose responsibility will be to pop new &amp;ldquo;jobs&amp;rdquo; off the
queue and execute them when available.&lt;/p&gt;

&lt;p&gt;The beauty of &lt;code&gt;Queue&lt;/code&gt; is that it is thread-safe; multiple threads in the thread pool an access this resource without corrupting its contents.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the revised implementation:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
    @size = size
    @jobs = Queue.new
    @pool = Array.new(size) do
      Thread.new do
        catch(:exit) do
          loop do
            job, args = @jobs.pop
            job.call(*args)
          end
        end
      end
    end
  end

  def schedule(*args, &amp;amp;block)
    @jobs &amp;lt;&amp;lt; [block, args]
  end

  def shutdown
    @size.times do
      schedule { throw :exit }
    end

    @pool.map(&amp;amp;:join)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s start with the &lt;code&gt;#schedule&lt;/code&gt; method. Where before we immediately creating a
new thread to call the block, we instead push the block and arguments onto the
new &lt;code&gt;@jobs&lt;/code&gt; queue instance variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def schedule(*args, &amp;amp;block)
  @jobs &amp;lt;&amp;lt; [block, args]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This instance variable is setup in the &lt;code&gt;#initialize&lt;/code&gt; method where we also
eagerly create the maximum number of threads that will become our worker &lt;code&gt;@pool&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def initialize(size:)
  @size = size
  @jobs = Queue.new
  @pool = Array.new(size) do
    Thread.new do
      catch(:exit) do
        loop do
          job, args = @jobs.pop
          job.call(*args)
        end
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each thread runs an infinite loop that repeatedly pops jobs of the queue with
&lt;code&gt;@jobs.pop&lt;/code&gt;. The &lt;a href="http://ruby-doc.org/stdlib-2.0.0/libdoc/thread/rdoc/Queue.html#method-i-pop"&gt;&lt;code&gt;Queue#pop&lt;/code&gt;&lt;/a&gt; method here will block when the queue is empty so the thread will happily wait for new jobs to be scheduled at this point.&lt;/p&gt;

&lt;p&gt;Notice also to &lt;a href="http://ruby-doc.org/core-2.3.0/Kernel.html#method-i-catch"&gt;&lt;code&gt;catch&lt;/code&gt;&lt;/a&gt; block. We break out of the thread loops by
pushing &lt;code&gt;throw :exit&lt;/code&gt; on to the job queue, once for each thread in the
&lt;code&gt;#shutdown&lt;/code&gt; method. This means that jobs currently executing when the shutdown
method is called will be able to complete before the threads can be joined.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def shutdown
  @size.times do
    schedule { throw :exit }
  end

  @pool.map(&amp;amp;:join)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a simple abstraction for handing concurrent work across a limited
number of threads. For more on this implementation, check out the original author&amp;rsquo;s &lt;a href="http://www.burgestrand.se/articles/quick-and-simple-ruby-thread-pool.html"&gt;blog post on
the subject&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/rossta/loves-enumerable/commit/cd6e89328948b9fd7e902764947163e4dd16b73d"&gt;Source for this changeset&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;In the Wild&lt;/h3&gt;

&lt;p&gt;Of course, if you&amp;rsquo;re planning on using a thread pool in production code, you&amp;rsquo;ll
may be better off leveraging the hard work of others. Our implementation omits
some key considerations, like providing reflection, handing timeouts, dealing with
exceptions, and better thread safety. Let&amp;rsquo;s look at some alternatives in the
community.&lt;/p&gt;

&lt;p&gt;The &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt; project provides a few extensions to the standard library &lt;code&gt;Thread&lt;/code&gt; class, including &lt;code&gt;Thread::Pool&lt;/code&gt;. Usage of &lt;code&gt;Thread::Pool&lt;/code&gt; is very similar to what we came up with on the surface.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;thread/pool&amp;#39;

pool = Thread.pool(4)

10.times {
  pool.process {
    sleep 2

    puts &amp;#39;lol&amp;#39;
  }
}

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This implementation goes farther to ensure standard locking functions to work
properly across multiple Ruby implementations. Among other things, it has
support for handling timeouts, methods for introspecting pool objects, like
&lt;code&gt;#running?&lt;/code&gt; and &lt;code&gt;#terminated?&lt;/code&gt;, and optimizations for dealing with unused
threads. On reading the source, my impression is the implementation was heavily inspired by &lt;a href="https://github.com/puma/puma/blob/32b1fb3742e5918e0e79ee705b48c912a1f0742d/lib/puma/thread_pool.rb"&gt;Puma::ThreadPool&lt;/a&gt;, a class used internally by the puma web server. You be the judge.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/celluloid/celluloid"&gt;Celluloid&lt;/a&gt;, the most famous
collection of concurrency abstractions, provides a thread pool class,
most commonly accessed via a class method provided by the
&lt;code&gt;Celluloid&lt;/code&gt; mixin.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class MyWorker
  include Celluloid

  def add_one(number)
    # roflscale computation goes here
    number + 1
  end
end

MyWorker.pool

pool.future(:add_one, 5).value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The new hotness for working with concurrency is the toolkit provided by &lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;. While &lt;code&gt;Celluloid&lt;/code&gt; is easy to get started with, &lt;code&gt;Concurrent&lt;/code&gt; is the &amp;ldquo;Swiss Army Knife&amp;rdquo;, providing a large array of abstractions and classes, including futures, promises, thread-safe collections, maybes, and so on. &lt;code&gt;Concurrent&lt;/code&gt; provides several different thread pool implementations for different purposes, each supporting a number of configurations, including min and max pool sizes, advanced shutdown behaviors, max queue size (along with a fallback policy when the job queue size is exceeded) to name a few.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = Concurrent::FixedThreadPool.new(5) # 5 threads
pool.post do
  # some parallel work
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Consider the &lt;a href="http://ruby-concurrency.github.io/concurrent-ruby/file.thread_pools.html"&gt;Thread Pool&lt;/a&gt; overview provided in the &lt;code&gt;Concurrent&lt;/code&gt; docs required reading.&lt;/p&gt;

&lt;p&gt;And, of course, the ultimate thread pool for Rails developers is &lt;a href="https://github.com/mperham/sidekiq"&gt;Sidekiq&lt;/a&gt;. Unlike the examples we&amp;rsquo;ve discussed so far, the components of the Sidekiq thread pool model are distributed: the caller, the job queue, and the threaded workers all run in separate processes, often on separate machines, in a production environment.&lt;/p&gt;

&lt;h3&gt;Credits&lt;/h3&gt;

&lt;p&gt;In preparing for this post, I read through the source of several thread pool
implementations from various sources, ranging from simple examples, to internal
interfaces, to public-facing libraries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.burgestrand.se/code/ruby-thread-pool/"&gt;A simple, annotated thread pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/meh/ruby-thread/blob/f25dd1184f4f4bee7cde0d54ad5ce5e32dc15279/lib/thread/pool.rb"&gt;&lt;code&gt;Thread::Pool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/celluloid/celluloid/blob/c54bbde76e6a71b44c3ca6d1abf71197c64d7614/lib/celluloid/group/pool.rb"&gt;&lt;code&gt;Celluloid::Group::Pool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby/blob/536478817a3d0440f00ac09098f3ba71f0d8ce7c/lib/concurrent/executor/ruby_thread_pool_executor.rb"&gt;&lt;code&gt;Concurrent::RubyThreadPoolExecutor&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/puma/puma/blob/32b1fb3742e5918e0e79ee705b48c912a1f0742d/lib/puma/thread_pool.rb"&gt;&lt;code&gt;Puma::ThreadPool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Though it&amp;rsquo;s well documented how much &lt;a href="http://adam.herokuapp.com/past/2009/8/13/threads_suck/"&gt;threads suck&lt;/a&gt;, that shouldn&amp;rsquo;t discourage Rubyists from trying to get some first-hand experience with working with threads, supporting classes from the standard library like &lt;code&gt;Queue&lt;/code&gt;, &lt;code&gt;Mutex&lt;/code&gt;, and &lt;code&gt;ConditionVariable&lt;/code&gt; and generic abstractions like &lt;code&gt;ThreadPool&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Connection Pool, the Sequel&lt;/h3&gt;

&lt;p&gt;Related, though not necessarily thread-based, is the concept of a connection
pool, which limits the number of network connections to a particular service.
You&amp;rsquo;ll find connection pools in &lt;a href="https://github.com/rails/rails/blob/107f4282bbfabc011d5ad3bcf3fb3c6fb812ad30/activerecord/lib/active_record/connection_adapters/abstract/connection_pool.rb"&gt;activerecord&lt;/a&gt;, &lt;a href="https://github.com/mongodb/mongo-ruby-driver/blob/eece2a769bbf1a302b2f70b23dc6a43490392979/lib/mongo/server/connection_pool.rb"&gt;mongodb&lt;/a&gt;, and, as a standalone
abstraction in the approrpriately-named,
&lt;a href="https://github.com/mperham/connection_pool"&gt;connection_pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s good to know
about connection pools for setting a connection to Redis from your Ruby
applications with the &lt;a href="https://github.com/redis/redis-rb"&gt;redis-rb&lt;/a&gt; gem. As of this writing, this client does not manage a connection pool for you, so &lt;a href="http://www.blrice.net/blog/2015/04/24/take-a-swim-in-the-connection-pool/"&gt;the common gotcha&lt;/a&gt; is a memory-leak that originates from creating a lot of open connections to the Redis server. You can avoid this with &lt;code&gt;ConnectionPool&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;redis = ConnectionPool.new { Redis.new }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much like &lt;code&gt;ThreadPool&lt;/code&gt;, having at least a cursory understanding of what&amp;rsquo;s happening
underneath can help you avoid issues with managing resources like network
connections.&lt;/p&gt;
</content>
  </entry>
</feed>
