<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>rossta.net</title>
  <subtitle>Ross Kaffenberger</subtitle>
  <id>https://rossta.net/</id>
  <link href="https://rossta.net/"/>
  <link href="https://rossta.net/feed.xml" rel="self"/>
  <updated>2016-04-15T20:00:00-04:00</updated>
  <author>
    <name>Ross Kaffenberger</name>
  </author>
  <entry>
    <title>Using Webpack with Middleman</title>
    <link rel="alternate" href="/blog/using-webpack-with-middleman.html"/>
    <id>/blog/using-webpack-with-middleman.html</id>
    <published>2016-04-15T20:00:00-04:00</published>
    <updated>2016-04-15T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;&lt;img src="/assets/images/blog/stock/tundra-hike-pexels-photo-9b187747.jpg"&gt;&lt;/p&gt;

&lt;p&gt;I’ve &lt;a href="/blog/why-i-ditched-wordpress-for-github.html"&gt;hosted this site on Github Pages&lt;/a&gt; with the &lt;a href="https://middlemanapp.com/"&gt;Middleman static site framework&lt;/a&gt; for several years now. To keep up with the most recent release of the framework, I decided to &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;upgrade the site to Middleman version 4&lt;/a&gt;. There were some significant changes...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;&lt;img src="/assets/images/blog/stock/tundra-hike-pexels-photo-9b187747.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve &lt;a href="/blog/why-i-ditched-wordpress-for-github.html"&gt;hosted this site on Github Pages&lt;/a&gt; with the &lt;a href="https://middlemanapp.com/"&gt;Middleman static site framework&lt;/a&gt; for several years now. To keep up with the most recent release of the framework, I decided to &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;upgrade the site to Middleman version 4&lt;/a&gt;. There were some significant changes to the configuration options and helper methods, which are &lt;a href="https://middlemanapp.com/basics/upgrade-v4/"&gt;well documented&lt;/a&gt; on the Middleman blog.&lt;/p&gt;

&lt;p&gt;By far the biggest change was the &lt;a href="https://middlemanapp.com/advanced/asset_pipeline/"&gt;removal of the Sprockets&lt;/a&gt; dependency for the asset pipeline. Sprockets was originally a big selling point for me when choosing Middleman years ago. As a Rails developer, I had a lot of familiarity with the Sprockets style directives for bundling JavaScript and CSS assets and could use the pipeline to transpile CoffeeScript and SCSS easily.&lt;/p&gt;

&lt;p&gt;Given the &amp;ldquo;explosion of front-end language and tooling&amp;rdquo; that has happened over the past few years, Sprockets has fallen behind in terms of speed and flexibility, among other things. With so many tools like Grunt, Gulp, Webpack, Browserify, Brunch, Brocolli&amp;emdash;name a few&amp;emdash;frameworks like Middleman can&amp;rsquo;t possibly support custom integrations for everything. Instead the Sprockets asset pipeline has been replaced with the &lt;code&gt;external_pipeline&lt;/code&gt; feature which allows Middleman to run &amp;ldquo;subprocesses&amp;rdquo; alongside the development server and build phase.&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;I surpise even myself sometimes. Middleman v4’s external pipeline feature is amazing. Integrated Webpack inside Middleman. Dev &amp;amp; build modes&lt;/p&gt;&amp;mdash; Thomas Reynolds (@tdreyno) &lt;a href="https://twitter.com/tdreyno/status/580115759768059904"&gt;March 23, 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;Exciting stuff.&lt;/p&gt;

&lt;h3&gt;Before the upgrade&lt;/h3&gt;

&lt;p&gt;Before I upgrading the Middleman version 4, I had been using built-in Sprockets integration to configure, import, and transpile assets in the rossta.net static build. This required some custom imports in my Middleman &lt;a href="https://github.com/rossta/rossta.github.com/blob/96444337b05e6a996b8a6f2b63f353194bc9eb4b/config.rb#L122"&gt;&lt;code&gt;config.rb&lt;/code&gt;&lt;/a&gt; to make &lt;a href="http://foundation.zurb.com/"&gt;Foundation&lt;/a&gt; CSS and JavaScript available to the Sprockets runtime.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# config.rb
compass_config do |config|
  # Require any additional compass plugins here.
  config.add_import_path &amp;quot;../bower_components/foundation/scss&amp;quot;

  # Set this to the root of your project when deployed:
  config.http_path = &amp;quot;/&amp;quot;
  config.css_dir = &amp;quot;stylesheets&amp;quot;
  config.sass_dir = &amp;quot;stylesheets&amp;quot;
  config.images_dir = &amp;quot;images&amp;quot;
  config.javascripts_dir = &amp;quot;javascripts&amp;quot;
end

after_configuration do
  @bower_config = JSON.parse(IO.read(&amp;quot;#{root}/.bowerrc&amp;quot;))
  sprockets.append_path File.join(root, @bower_config[&amp;quot;directory&amp;quot;])

  sprockets.import_asset &amp;quot;foundation/js/vendor/modernizr.js&amp;quot;
  sprockets.import_asset &amp;quot;foundation/js/vendor/jquery.js&amp;quot;
  sprockets.import_asset &amp;quot;foundation/js/vendor/jquery.cookie.js&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This configuration made it possible to require assets in JavaScript with the
&amp;ldquo;magic&amp;rdquo; Sprocket require comments, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;// 3rd party javascript
//= require foundation/js/vendor/jquery
//= require foundation/js/vendor/jquery.cookie
//= require foundation

// My custom javascript
//= require zen
//= require tracking
//= require onload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With Sprockets dropped in Middleman version 4, this approach would no longer be
possible so I had to rethink the build pipeline. I preferred to support multiple
bundles and also wanted to upgrade my custom JavaScript to ES2015 syntax. For
this, &lt;a href="#"&gt;Webpack&lt;/a&gt; appeared to offer some nice advantages, though, many of the
build tools and systems mentioned earlier would also make good choices and fit
right into the new Middleman external pipeline feature.&lt;/p&gt;

&lt;h3&gt;Enabling the External Pipeline&lt;/h3&gt;

&lt;p&gt;First step was to upgrade Middleman and remove Sprockets-based gems and
configuration from &lt;code&gt;config.rb&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;gem &amp;quot;middleman&amp;quot;, &amp;quot;~&amp;gt; 4&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ bundle update middleman
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also deleted my Bower configuration and dependencies in favor of switching to
&lt;code&gt;npm&lt;/code&gt; to manage third-party assets. To setup my npm assets:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm init
$ npm install --save-dev wepback
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The external pipeline feature in Middleman provides a mechanism for the
middleman development server to manage processes that live outside the Ruby
runtime. For Webpack, this means telling Middleman how to trigger the &lt;a href="https://webpack.github.io/docs/tutorials/getting-started/#setup-compilation"&gt;Webpack
compilation command&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;config.rb&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;activate :external_pipeline,
         name: :webpack,
         command: build? ?
         &amp;quot;./node_modules/webpack/bin/webpack.js --bail -p&amp;quot; :
         &amp;quot;./node_modules/webpack/bin/webpack.js --watch -d --progress --color&amp;quot;,
         source: &amp;quot;.tmp/dist&amp;quot;,
         latency: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I copied this configuration directly from the &lt;a href="middleman/middleman-core/lib/middleman-core/extensions/external_pipeline.rb"&gt;Middleman guides source&lt;/a&gt; which I learned made the same change recently.&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Commit upgrading Middleman Guides from Asset Pipeline to Webpack: &lt;a href="https://t.co/uP4LH19SfJ"&gt;https://t.co/uP4LH19SfJ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Thomas Reynolds (@tdreyno) &lt;a href="https://twitter.com/tdreyno/status/678711274516033536"&gt;December 20, 2015&lt;/a&gt;&lt;/blockquote&gt;

&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;Specifying &lt;code&gt;activate :external_pipeline&lt;/code&gt; enables Middleman&amp;rsquo;s external pipeline
extension (&lt;a href="https://github.com/middleman/middleman/blob/6872e07d34ab037897e8466db634efb9b49b4af5/middleman-core/lib/middleman-core/extensions/external_pipeline.rb"&gt;source&lt;/a&gt;). The three required options are worth noting:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# middleman/middleman-core/lib/middleman-core/extensions/external_pipeline.rb
option :name, nil, &amp;#39;The name of the pipeline&amp;#39;, required: true
option :command, nil, &amp;#39;The command to initialize&amp;#39;, required: true
option :source, nil, &amp;#39;Path to merge into sitemap&amp;#39;, required: true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key point to understand here is Middleman will expect the external pipeline to output the compiled files to a directory which you specify here as &lt;code&gt;:source&lt;/code&gt;. We arbitrarily chose &lt;code&gt;.tmp/dist&lt;/code&gt; but it doesn&amp;rsquo;t matter so long as you use a dedicated destination. We&amp;rsquo;ll need to configure webpack separately to send its output here.&lt;/p&gt;

&lt;p&gt;Middleman will trigger the &lt;code&gt;:command&lt;/code&gt; in a thread and buffer its output to the Middleman logger so you can see what&amp;rsquo;s going on all in a single output stream. We use the &lt;code&gt;build?&lt;/code&gt; flag to modify the &lt;code&gt;webpack&lt;/code&gt; command for builds (which will fail fast) and development, where we want to watch for file changes and reload automatically.&lt;/p&gt;

&lt;p&gt;An optional &lt;code&gt;:latency&lt;/code&gt; can be used to set the seconds of delay between changes and refreshes.&lt;/p&gt;

&lt;h3&gt;Setting up Webpack&lt;/h3&gt;

&lt;p&gt;Webpack as a dizzying array of plugins and configuration options. The bare minimum to get JavaScript working with Webpack and Middleman is to set an &lt;code&gt;entry&lt;/code&gt; option to declare the primary source file(s) entry point and where it should compile to as the &lt;code&gt;output&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;# webpack.config.js
var webpack = require(&amp;#39;webpack&amp;#39;);

module.exports = {
  entry: {
    site: &amp;#39;./source/javascripts/site.js&amp;#39;
  },

  resolve: {
    root: __dirname + &amp;#39;/source/javascripts&amp;#39;,
  },

  output: {
    path: __dirname + &amp;#39;/.tmp/dist&amp;#39;,
    filename: &amp;#39;javascripts/[name].js&amp;#39;,
  },
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is not a full Webpack tutorial, but it worth noting we can use Webpack to do:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Transpile from ES2015 syntax&lt;/strong&gt;. We can pull in Babel dependencies and desired presets from &lt;code&gt;npm&lt;/code&gt; and declare &lt;code&gt;loaders&lt;/code&gt; in Webpack config to customize the compilation stages. This meant I was able to rewrite much of my custom JavaScript from ES5 to ES2015.&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm install --save-dev babel babel-loader babel-preset-es2015 babel-preset-stage-0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;# webpack.config.js
module.exports = {
  // ...

  module: {
    loaders: [
      {
        test: /source\/assets\/javascripts\/.*\.js$/,
        exclude: /node_modules|\.tmp|vendor/,
        loader: &amp;#39;babel-loader&amp;#39;,
        query: {
          presets: [&amp;#39;es2015&amp;#39;, &amp;#39;stage-0&amp;#39;]
        },
      },
      // ...
    ],
  }

  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Declare global variables&lt;/strong&gt;. I rely on the jQuery &lt;code&gt;$&lt;/code&gt; sign in enough places that
I decided to configure Webpack to treat it as a global variable so it would be
available in each of my JavaScript source files without declaring a separate
&lt;code&gt;import&lt;/code&gt; everywhere. This is done with the &lt;code&gt;webpack.ProvidePlugin&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;# webpack.config.js
module.exports = {
  // ...

  plugins: [
    // ...
    new webpack.ProvidePlugin({
      $: &amp;quot;jquery&amp;quot;,
      jQuery: &amp;quot;jquery&amp;quot;,
      &amp;quot;window.jQuery&amp;quot;: &amp;quot;jquery&amp;quot;
    }),
  ],

  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Transpile SCSS to CSS&lt;/strong&gt;. Though Middleman still provides an integration with
Compass, &lt;a href="https://benfrain.com/lightning-fast-sass-compiling-with-libsass-node-sass-and-grunt-sass/"&gt;word on the street&lt;/a&gt; is that Node tools like &lt;code&gt;node-sass&lt;/code&gt; out-perform the Ruby Compass implementation. With the node-sass and some additional Webpack dependencies, we can transpile SCSS with Webpack to a separate css bundle:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;$ npm install --save-dev node-sass sass-loader extract-text-webpack-plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;# webpack.config.js
var ExtractTextPlugin = require(&amp;#39;extract-text-webpack-plugin&amp;#39;);

module.exports = {
  // ...

  entry: {
    styles: &amp;#39;./source/assets/stylesheets/styles.scss&amp;#39;,
    // ...
  },

  module: {
    loaders: [
      // ...
      {
        test: /.*\.scss$/,
        loader: ExtractTextPlugin.extract(
          &amp;quot;style&amp;quot;,
          &amp;quot;css!sass?sourceMap&amp;amp;includePaths[]=&amp;quot; + __dirname + &amp;quot;/node_modules&amp;quot;
        )
      },
      // Load plain-ol&amp;#39; vanilla CSS
      { test: /\.css$/, loader: &amp;quot;style!css&amp;quot; },
    ],
  }
  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Enable feature flags&lt;/strong&gt;. &lt;a href="https://tenderlovemaking.com/2016/02/05/i-am-a-puts-debuggerer.html"&gt;I love puts debugging&lt;/a&gt; so I&amp;rsquo;ve got quite a few log statements in my JavaScript code. I don&amp;rsquo;t really want these log statements in the production build of the website, so I can use Webpack to allow me to enable logging only in development:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;# webpack.config.js
var definePlugin = new webpack.DefinePlugin({
  __DEVELOPMENT__: JSON.stringify(JSON.parse(process.env.BUILD_DEVELOPMENT || false)),
  __PRODUCTION__: JSON.stringify(JSON.parse(process.env.BUILD_PRODUCTION || false))
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tell Webpack to makde the &lt;code&gt;__DEVELOPMENT__&lt;/code&gt; and &lt;code&gt;__PRODUCTION__&lt;/code&gt; variables
available based on the presence on the &lt;code&gt;BUILD_DEVELOPMENT&lt;/code&gt; and
&lt;code&gt;BUILD_DEVELOPMENT&lt;/code&gt; environment variables. I pass these variables to the webpack
commands I&amp;rsquo;m using in &lt;code&gt;config.rb&lt;/code&gt; for the build and development Middleman
contexts respectively:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;activate :external_pipeline,
         name: :webpack,
         command: build? ?
         &amp;quot;BUILD_PRODUCTION=1 ./node_modules/webpack/bin/webpack.js --bail -p&amp;quot; :
         &amp;quot;BUILD_DEVELOPMENT=1 ./node_modules/webpack/bin/webpack.js --watch -d --progress --color&amp;quot;,
         source: &amp;quot;.tmp/dist&amp;quot;,
         latency: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I can then take advantage of feature flags in my JavaScript:&lt;/p&gt;

&lt;pre&gt;&lt;code class="javascript"&gt;function log() {
  if (__DEVELOPMENT__) {
    console.log(...arguments);
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My development experience is greatly enhanced with the auto-recompile feature of
webpack along with the &lt;code&gt;middleman-livereload&lt;/code&gt; extension. Though I haven&amp;rsquo;t tried
the &lt;code&gt;webpack-dev-server&lt;/code&gt; and &lt;a href="https://webpack.github.io/docs/hot-module-replacement-with-webpack.html"&gt;hot-reloading of Webpack modules&lt;/a&gt;, it seems possible to set this up to work with Middleman.&lt;/p&gt;

&lt;p&gt;You can go much further with Webpack of course. For more info, check out the &lt;a href="https://webpack.github.io/"&gt;Webpack guides&lt;/a&gt; and Pete Hunt&amp;rsquo;s &lt;a href="https://github.com/petehunt/webpack-howto"&gt;Webpack How-to&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Moving away from Sprockets&lt;/h3&gt;

&lt;p&gt;The Middleman team has taken a big risk in dropping support for the primary asset management solution for Rails developers, likely the primary maintainers of Middleman apps. I believe it was the right choice. As someone who has been through the upgrade process, I can confirm it was challenging, but I have seen how great the payoff can be.&lt;/p&gt;

&lt;p&gt;In my opinion, if the Rails community wishes to stay relevant in the coming years, it would be wise to adopt a similar strategy: to &amp;ldquo;future proof&amp;rdquo; the rapidly changing front-end environment, Rails should drop Sprockets and embrace the external pipeline like Middleman.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Ancient City Ruby Snake Case</title>
    <link rel="alternate" href="/blog/ancient-city-snake-case.html"/>
    <id>/blog/ancient-city-snake-case.html</id>
    <published>2016-04-11T20:00:00-04:00</published>
    <updated>2016-04-11T20:00:00-04:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;&lt;img src="/assets/images/blog/stock/snakes-pexels-photo-88dd6b6b.jpg"&gt;&lt;/p&gt;

&lt;p&gt;Last week &lt;a href="#"&gt;I spoke&lt;/a&gt; at &lt;a href="#"&gt;Ancient City Ruby Conference&lt;/a&gt; where the organizers encouraged people to participate in a Ruby programming challenge called &lt;a href="http://www.ancientcityruby.com/snake_case/"&gt;Snake Case&lt;/a&gt;. I benchmarked a number of different ways to solve the challenge in Ruby and present the results...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;&lt;img src="/assets/images/blog/stock/snakes-pexels-photo-88dd6b6b.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;Last week &lt;a href="#"&gt;I spoke&lt;/a&gt; at &lt;a href="#"&gt;Ancient City Ruby Conference&lt;/a&gt; where the organizers encouraged people to participate in a Ruby programming challenge called &lt;a href="http://www.ancientcityruby.com/snake_case/"&gt;Snake Case&lt;/a&gt;. I benchmarked a number of different ways to solve the challenge in Ruby and present the results here.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the challenge:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;THE ANCIENT CITY RUBY 2016 PROGRAMMING CHALLENGE&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ve just arrived in sunny St. Augustine, and find yourself amazed by the visionary civic planning that would result in the area in which you now stand: a street grid exactly 10 blocks square.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;re in the northwest corner of this 10 by 10 block area, and would like to take a scenic walk to the southeast corner, while only ever moving south or east.&lt;/p&gt;

&lt;p&gt;As you begin walking, you wonder to yourself, &amp;ldquo;how many different paths could I take from this northwest corner to the southeast corner?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;You quickly note that if the downtown area were only a 2 block by 2 block grid, there would be 6 distinct paths from one corner to the other:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/snake-case-blocks-20fdedd0.png" /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth nothing that the intent of the problem was to calculate the correct
number of &amp;ldquo;optimal&amp;rdquo; paths along the blocks, so a meandering path does not count.
Starting at the northwest corner of a 10x10 grid, there will be 20 moves in
any valid path: 10 moves south and 10 moves east.&lt;/p&gt;

&lt;h3&gt;Recursion&lt;/h3&gt;

&lt;p&gt;How about a recursive solution? Consider that for any location &lt;code&gt;h, w&lt;/code&gt; on the grid, there are either one or two incoming paths oriented in the south or west direction, one coming from neighbor &lt;code&gt;h-1, w&lt;/code&gt; and the other coming from neighbor &lt;code&gt;h, w-1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This means that the solution for the given location is the sum of two subproblems: the number of paths arriving at location &lt;code&gt;h-1, w&lt;/code&gt; plus the number of paths arriving at location &lt;code&gt;h, w-1&lt;/code&gt;. In pseudocode:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(h, w) = path_count(h-1, w) + path_count(h, w-1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exception to this rule is if either &lt;code&gt;h&lt;/code&gt; or &lt;code&gt;w&lt;/code&gt; are on the &amp;ldquo;edges&amp;rdquo;, meaning the
value is 0. In this case, there&amp;rsquo;s only 1 path that can reach these locations.&lt;/p&gt;

&lt;p&gt;Now we have enough information to construct a recursive solution to the problem:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# recursive
def path_count(h, w)
  return 1 if h == 0 || w == 0

  path_count(h-1, w) + path_count(h, w-1)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The expected result for a 10x10 grid is &lt;code&gt;184,756&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(10, 10)
# =&amp;gt; 184756
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works!  Let&amp;rsquo;s consider some alternative approaches.&lt;/p&gt;

&lt;h3&gt;Binary and Binomial&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://rayhightower.com/"&gt;Ray Hightower&lt;/a&gt;, who also &lt;a href="http://rayhightower.com/blog/2016/04/08/ancient-city-ruby-2016/"&gt;spoke at ACR&lt;/a&gt;, recently published a nice writeup of a &lt;a href="http://rayhightower.com/blog/2016/04/11/comparing-ruby-c-and-go/"&gt;&amp;ldquo;brute force&amp;rdquo; solution in Ruby, C, and Go&lt;/a&gt;. Please check out his detailed explanation of both a mathematical and brute force solution in Ruby.&lt;/p&gt;

&lt;p&gt;The mathematics approach is a factorial: given a 10x10 grid, we want to
construct 20 moves where 10 moves are &amp;ldquo;south&amp;rdquo; and 10 moves are &amp;ldquo;east&amp;rdquo;. We could
represent this conceptually as a bit map, where the total number of bits is
20^2, or &lt;code&gt;(h+w)**2&lt;/code&gt; where &lt;code&gt;h&lt;/code&gt; is the height and &lt;code&gt;w&lt;/code&gt; is the width of the grid. It
turns out this can be represented as a &lt;a href="https://en.wikipedia.org/wiki/Binomial_coefficient"&gt;binomial coefficient&lt;/a&gt; often expressed as:&lt;/p&gt;

&lt;p&gt;&lt;img src="/assets/images/blog/binomial-coefficient-c44f945f.gif" /&gt;&lt;/p&gt;

&lt;p&gt;Ray provided a nice LaTex-formatted description of the mathematics involved. Translated into a general Ruby function, this can be expressed in factorials.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# factorial
def path_count(h, w)
  (h+w).downto(h+1).reduce(:*) / w.downto(1).reduce(:*)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function gives the correct solution for 10x10: &lt;code&gt;184,756&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;path_count(10, 10)
# =&amp;gt; 184756
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &amp;ldquo;brute-force&amp;rdquo; solution counts up all the &amp;ldquo;1&amp;rdquo; bits in all possible combination
of bits from 0 to 2^(h+w), or 2^20 in our case of a 10x10 grid.&lt;/p&gt;

&lt;p&gt;Expressed in a general Ruby function:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# brute force
def path_count(h, w)
  (0..(2**(h+w))).count { |x| x.to_s(2).chars.count(&amp;quot;1&amp;quot;) == n }
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The total number of bits to explore is equal to &lt;code&gt;2**(h+w)&lt;/code&gt;. We count how many of
those numbers, when expressed as binary with &lt;code&gt;x.to_s(2)&lt;/code&gt; have 10 &amp;ldquo;1&amp;rdquo; bits.&lt;/p&gt;

&lt;h3&gt;Iteration&lt;/h3&gt;

&lt;p&gt;The recursive solution asks us to solve the problem backwards in a way: given
the destination, figure out the solution by solving the problem for the nearest previous destinations and the ones that came before those and so on. What if we could &amp;ldquo;build up&amp;rdquo; to the solution instead? We can take an iterative approach in stead.&lt;/p&gt;

&lt;p&gt;Imagine each corner or &amp;ldquo;node&amp;rdquo; of the grid can be represented as the number of paths leading to it. For a 5x5 grid, there are 6 nodes and each would have a value of &lt;code&gt;1&lt;/code&gt;, since there is only one way to get to those nodes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1  # first row of a 5x5 grid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The second row gets interesting. Each node will be the sum of paths leading to
the nodes immediately north and west. So, the first node in the second row is
still just &lt;code&gt;1&lt;/code&gt; since no paths lie to the west and the value of the node
immediately to the north is &lt;code&gt;1&lt;/code&gt;. The second node in the second row gets a value
of &lt;code&gt;2&lt;/code&gt; since the node to the west is now &lt;code&gt;1&lt;/code&gt; and the node to the north is also &lt;code&gt;1&lt;/code&gt;. Continuing on, this gives a second row of &lt;code&gt;1 2 3 4 5 6&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1
1--2--3--4--5--6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The third row:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1--1--1--1--1--1
1--2--3--4--5--6
1--3--6--10-15-21
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And so on&amp;hellip; The number of paths for a given grid would simply be the value of
the last node in the last row. Let&amp;rsquo;s implement this in Ruby:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# iterative
def path_count(h, w)
  row = [1] * (w+1) # first row of &amp;quot;1s&amp;quot;

  h.times do
    row = row.reduce([]) { |acc, p| acc &amp;lt;&amp;lt; (p + acc.last.to_i)  }
  end

  row.last
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;reduce&lt;/code&gt; expression generates a row from the previous one and the values of
each previous member of the current row. The function returns the last member of
the last row.&lt;/p&gt;

&lt;p&gt;Since &lt;a href="/talks/ruby-enumerator.html"&gt;I gave a talk about Enumerator at Ancient City&lt;/a&gt; I decided it would only
be appropriate if I solved the Snake Case challenge using an &lt;code&gt;Enumerator&lt;/code&gt;. We
can extract an Enumerator from the iterative solution to represent a function that generates each row of the grid:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def grid(h, w)
  return to_enum(:grid, h, w) unless block_given?

  row = [1] * (w+1)
  yield row

  h.times do
    row = row.reduce([]) { |acc, p| acc &amp;lt;&amp;lt; (p + acc.last.to_i)  }
    yield row
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two key changes have been made. We&amp;rsquo;ve inserted &lt;code&gt;yield&lt;/code&gt; statements to allow the
caller to receive each row of the grid as it is generated. We also  &amp;ldquo;enumeratorize&amp;rdquo; our iterative function by converting the behavior of the function into an &lt;code&gt;Enumerator&lt;/code&gt; when no block is given in the first line.&lt;/p&gt;

&lt;p&gt;Calling &lt;code&gt;grid(10, 10)&lt;/code&gt; returns an &lt;code&gt;Enumerator&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;grid(10, 10)
# =&amp;gt; #&amp;lt;Enumerator: ...&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Calling &lt;code&gt;to_a&lt;/code&gt; on our &lt;code&gt;Enumerator&lt;/code&gt; creates each &amp;ldquo;node&amp;rdquo; value:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;grid(10, 10).to_a
# =&amp;gt; [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
# [1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66],
# [1, 4, 10, 20, 35, 56, 84, 120, 165, 220, 286],
# [1, 5, 15, 35, 70, 126, 210, 330, 495, 715, 1001],
# [1, 6, 21, 56, 126, 252, 462, 792, 1287, 2002, 3003],
# [1, 7, 28, 84, 210, 462, 924, 1716, 3003, 5005, 8008],
# [1, 8, 36, 120, 330, 792, 1716, 3432, 6435, 11440, 19448],
# [1, 9, 45, 165, 495, 1287, 3003, 6435, 12870, 24310, 43758],
# [1, 10, 55, 220, 715, 2002, 5005, 11440, 24310, 48620, 92378],
# [1, 11, 66, 286, 1001, 3003, 8008, 19448, 43758, 92378, 184756]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the last value of the last row is the correct answer to our path count
challenge.&lt;/p&gt;

&lt;p&gt;For our revised &lt;code&gt;path_count&lt;/code&gt; method, we simply want to retrieve the last member of the last row:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# enumeartive
def path_count(h, w)
  grid(h, w).drop(h-1).last.last
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that the nodes of this grid follow the pattern of Pascal&amp;rsquo;s
Triangle expanding from the northwest corner. Pascal&amp;rsquo;s Triangle is well suited for an Enumerator function as &lt;a href="/blog/pascals-triangle-with-rubys-enumerator.html"&gt;I&amp;rsquo;ve written about previously&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Tradeoffs&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ve described a number of ways to solve Snake Case and each comes with
tradeoffs.&lt;/p&gt;

&lt;p&gt;In terms of readability, I would personally place the solutions in the following
order from most to least readable:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Recursive&lt;/li&gt;
&lt;li&gt;Iterative&lt;/li&gt;
&lt;li&gt;Brute force&lt;/li&gt;
&lt;li&gt;Factorial&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At least for me, the recursive solution is the easiest to wrap my
head around and most readable result. It&amp;rsquo;s easy to see from the recursive implementation how the problem may be divided into smaller sub-problems. The others require some deeper visualization and/or mathematical understanding to &amp;ldquo;grok&amp;rdquo; I feel. The factorial expression seems farthest removed conceptually from the description of the problem. In other words, it&amp;rsquo;s most at odds with my intuition, but I&amp;rsquo;m also not a mathematician so am less inclined to think in those terms.&lt;/p&gt;

&lt;p&gt;How do they compare performance-wise? With &lt;code&gt;benchmark-ips&lt;/code&gt; we can compare the
iterations/second and share the results.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a file that defines each of the approaches we&amp;rsquo;ve described in separate
modules and benchmarks the performance for calculating the result for a 10x10
grid. (&lt;a href="https://github.com/rossta/loves-enumerable/blob/edbab0fcb2aeac65a7b34d9fa603b3aa58563b4f/code/snake_case.rb"&gt;Full source&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Running on my mid-2014 MacBook Pro with MRI ruby-2.3:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;quot;benchmark/ips&amp;quot;

Benchmark.ips do |x|
  x.report(&amp;quot;snake case factorial&amp;quot;) do
    SnakeCase::Factorial.path_count(10, 10)
  end

  x.report(&amp;quot;snake case brute force&amp;quot;) do
    SnakeCase::Bruteforce.path_count(10, 10)
  end

  x.report(&amp;quot;snake case recursive&amp;quot;) do
    SnakeCase::Recursive.path_count(10, 10)
  end

  x.report(&amp;quot;snake case iterative&amp;quot;) do
    SnakeCase::Iterative.path_count(10, 10)
  end

  x.report(&amp;quot;snake case enumerative&amp;quot;) do
    SnakeCase::Enumerative.path_count(10, 10)
  end

  x.compare!
end

# $ SHARE=1 ruby code/snake_case.rb
# Calculating -------------------------------------
# snake case factorial    34.658k i/100ms
# snake case brute force
#                          1.000  i/100ms
# snake case recursive     5.000  i/100ms
# snake case iterative     4.920k i/100ms
# snake case enumerative
#                          4.109k i/100ms
# -------------------------------------------------
# snake case factorial    456.100k (± 7.8%) i/s -      2.287M
# snake case brute force
#                           0.325  (± 0.0%) i/s -      2.000  in   6.161730s
# snake case recursive     50.084  (±10.0%) i/s -    250.000
# snake case iterative     52.616k (± 5.3%) i/s -    265.680k
# snake case enumerative
#                          42.875k (± 7.1%) i/s -    213.668k
#
# Comparison:
# snake case factorial:   456100.0 i/s
# snake case iterative:    52615.9 i/s - 8.67x slower
# snake case enumerative:    42874.6 i/s - 10.64x slower
# snake case recursive:       50.1 i/s - 9106.72x slower
# snake case brute force:        0.3 i/s - 1405090.92x slower
#
# Shared at: https://benchmark.fyi/f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The factorial solution is orders of magnitude faster than the others. The iterative (and relatively similar enumerative) examples are only about ~10x slower than the factorial version while the recursive solution is almost 10,000x slower. The brute force solution is over a million-times slower. Even though the standard deviation in some of the results was fairly large, the differences across strategies appear conclusive.&lt;/p&gt;

&lt;p&gt;The maintainer of &lt;code&gt;benchmark-ips&lt;/code&gt;, &lt;a href="https://twitter.com/evanphx"&gt;Evan Phoenix&lt;/a&gt;, added the ability to share benchmark results online. You can see &lt;a href="https://benchmark.fyi/f"&gt;the results for this test on benchmark.fyi&lt;/a&gt;. The &lt;a href="https://github.com/rossta/loves-enumerable/blob/edbab0fcb2aeac65a7b34d9fa603b3aa58563b4f/code/snake_case.rb"&gt;full source code is also on GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;And the winner is&amp;hellip;&lt;/h3&gt;

&lt;p&gt;All of the above!&lt;/p&gt;

&lt;p&gt;This serves as a good illustration of how there&amp;rsquo;s often no single &amp;ldquo;best&amp;rdquo; way to
solve a problem with considering the circumstance. In a situation where
performance matters, the mathematical approach has a clear advantage, but
sacrifices readability. I might be inclined to choose the iterative or recursive
approach in situations where performance isn&amp;rsquo;t the key concern.&lt;/p&gt;

&lt;p&gt;Given my preference for &lt;a href="https://rossta.net/blog/series/enumerable.html"&gt;Enumerable&lt;/a&gt;, I personally love the enumerative approach, but, as &lt;a href="https://rossta.net/talks/ruby-enumerator.html"&gt;I discussed at Ancient City Ruby&lt;/a&gt;, I doubt most would agree.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Thread Pool - A Ruby Antihero</title>
    <link rel="alternate" href="/blog/a-ruby-antihero-thread-pool.html"/>
    <id>/blog/a-ruby-antihero-thread-pool.html</id>
    <published>2016-03-01T19:00:00-05:00</published>
    <updated>2016-03-01T19:00:00-05:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;&lt;img alt="Deadpool" src="/assets/images/blog/deadpool-b5499244.jpg"&gt;&lt;/p&gt;

&lt;p&gt;One of the fundamental concepts in key Ruby libraries that embrace
concurrency is the &lt;a href="https://en.wikipedia.org/wiki/Thread_pool"&gt;thread pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can find examples of thread pool implementations in gems like
&lt;a href="https://github.com/puma/puma"&gt;puma&lt;/a&gt;,
&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;,
&lt;a href="https://github.com/celluloid/celluloid"&gt;celluloid&lt;/a&gt;,
&lt;a href="https://github.com/bruceadams/pmap"&gt;pmap&lt;/a&gt;,
&lt;a href="https://github.com/grosser/parallel/blob/6ebee4ff5c0933da241a182e366eee9227b49764/lib/parallel.rb#L66"&gt;parallel&lt;/a&gt;,
and &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A thread pool...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;&lt;img alt="Deadpool" src="/assets/images/blog/deadpool-b5499244.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;One of the fundamental concepts in key Ruby libraries that embrace
concurrency is the &lt;a href="https://en.wikipedia.org/wiki/Thread_pool"&gt;thread pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can find examples of thread pool implementations in gems like
&lt;a href="https://github.com/puma/puma"&gt;puma&lt;/a&gt;,
&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;,
&lt;a href="https://github.com/celluloid/celluloid"&gt;celluloid&lt;/a&gt;,
&lt;a href="https://github.com/bruceadams/pmap"&gt;pmap&lt;/a&gt;,
&lt;a href="https://github.com/grosser/parallel/blob/6ebee4ff5c0933da241a182e366eee9227b49764/lib/parallel.rb#L66"&gt;parallel&lt;/a&gt;,
and &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A thread pool is an abstraction for re-using a limited number of threads to
performing concurrent work.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Thread pool - no relation" src="/assets/images/blog/threadpool-428287d8.png" /&gt;&lt;/p&gt;

&lt;p&gt;General usage of a thread pool might look something like the following, where the &lt;code&gt;:size&lt;/code&gt;
represents the maximum number of threads open at any given time.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = ThreadPool.new(size: 5)

10_000.times do
  pool.schedule { do_work }
end

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The calculation would be performed 10,000 times across five separate threads.&lt;/p&gt;

&lt;p&gt;To get a better understanding of how thread pools work, let&amp;rsquo;s implement a thread
pool in test-driven fashion.&lt;/p&gt;

&lt;aside class="callout panel"&gt;
&lt;p&gt;
  The code samples in this post are run on &lt;code&gt;rubinius-3.14&lt;/code&gt; to take advantage of
  parallel processing. As you may know, MRI&amp;rsquo;s
&lt;a href="http://www.jstorimer.com/blogs/workingwithcode/8085491-nobody-understands-the-gil"&gt;global interpreter lock&lt;/a&gt;
ensures only one code can execute Ruby code at any one time.
&lt;/p&gt;
&lt;/aside&gt;

&lt;h3&gt;Don&amp;rsquo;t be afraid&lt;/h3&gt;

&lt;p&gt;Before we dive in, let&amp;rsquo;s acknowledge that Rubyists, and most OO programmers in general,
are taught to fear multi-threaded concurrency.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;first rule&lt;/em&gt; of concurrency on the JRuby wiki, a Ruby implementation
designed to take advantage of native operating systems threads, is this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don&amp;rsquo;t do it, if you can avoid it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the purpose of this post, I&amp;rsquo;m going to assume the author means &amp;ldquo;in
production&amp;rdquo;. In the safety of your development environment, playing with
concurrency in Ruby can be a tremendous learning opportunity.&lt;/p&gt;

&lt;h3&gt;A simple thread pool&lt;/h3&gt;

&lt;p&gt;So we&amp;rsquo;ll implement a simple thread pool guided by tests. Our thread pool will use the
interface we described earlier while limiting the number of threads
used to carry out a set of concurrent &amp;ldquo;jobs&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = ThreadPool.new(size: 5)

pool.schedule { do_work }

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Basic usage&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ll start with a thread pool that doesn&amp;rsquo;t do any concurrent processing.
It will execute the block given to its &lt;code&gt;#schedule&lt;/code&gt; method
directly. Though we&amp;rsquo;ll add other tests later to exercise concurrency in the
implementation, this first test will assume the concurrency is already
implemented.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s our first test.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;minitest/autorun&amp;#39;
require &amp;#39;minitest/pride&amp;#39;
require_relative &amp;#39;./thread_pool&amp;#39;

class TestThreadPool &amp;lt; Minitest::Test
  def test_basic_usage
    pool_size = 5
    pool = ThreadPool.new(size: pool_size)

    mutex = Mutex.new

    iterations = pool_size * 3
    results = Array.new(iterations)

    iterations.times do |i|
      pool.schedule do
        mutex.synchronize do
          results[i] = i + 1
        end
      end
    end
    pool.shutdown

    assert_equal(1.upto(pool_size * 3).to_a, results)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break it down. To test the basic usage of a thread pool scheduler, we&amp;rsquo;ll pass in an array and
augment it with in the scheduled blocks. Because &lt;a href="http://www.jstorimer.com/pages/ruby-core-classes-arent-thread-safe"&gt;&lt;code&gt;Array&lt;/code&gt; is not thread safe&lt;/a&gt;,
we need to use a &lt;a href="http://ruby-doc.org/core-2.2.0/Mutex.html"&gt;&lt;code&gt;Mutex&lt;/code&gt;&lt;/a&gt; object to lock the pooled threads while adding items to the array.&lt;/p&gt;

&lt;p&gt;The key snippet is here:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool.schedule do
  mutex.synchronize do
    results[i] = i + 1
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The test asserts that the results match &lt;code&gt;1.upto(15)&lt;/code&gt; as an array.&lt;/p&gt;

&lt;p&gt;To make the tests pass:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
  end

  def schedule(*args, &amp;amp;block)
    block.call(args)
  end

  def shutdown
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ve just stubbed out the &lt;code&gt;#initialize&lt;/code&gt; and &lt;code&gt;#shutdown&lt;/code&gt; methods since
additional behavior isn&amp;rsquo;t needed to get the tests to pass.&lt;/p&gt;

&lt;p&gt;You can see the source for &lt;a href="https://github.com/rossta/loves-enumerable/commit/fcd81ec86ae3525d8f0a3acf914507e2962fb962"&gt;this changeset on Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Saving time&lt;/h3&gt;

&lt;p&gt;Our next test will demonstrate that we&amp;rsquo;re actually taking advantage of concurrency by
(crudely) measuring the time taken to process multiple jobs.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll use a small test helper method to measure the number of
seconds elapsed during execution:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def time_taken
  now = Time.now.to_f
  yield
  Time.now.to_f - now
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our test will schedule 5 jobs that will each sleep for 1 second.
If the jobs executed serially, the total execution time would be at least 5
seconds. Running in parallel on Rubinius, we&amp;rsquo;d expect threaded-execution of 5 jobs
across 5 threads to take less time.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def test_time_taken
  pool_size = 5
  pool = ThreadPool.new(size: pool_size)
  elapsed = time_taken do
    pool_size.times do
      pool.schedule { sleep 1 }
    end
    pool.shutdown
  end
  assert_operator 4.5, :&amp;gt;, elapsed,
    &amp;#39;Elapsed time was too long: %.1f seconds&amp;#39; % elapsed
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This test fails with our first pass-through implementation of &lt;code&gt;ThreadPool&lt;/code&gt;. We
can make this test pass by wrapping each scheduled job in its own thread.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
    @pool = []
  end

  def schedule(*args, &amp;amp;block)
    @pool &amp;lt;&amp;lt; Thread.new { block.call(args) }
  end

  def shutdown
    @pool.map(&amp;amp;:join)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We push each of these threads onto an array, &lt;code&gt;@pool&lt;/code&gt;, which we can use to join
the threads during the &lt;code&gt;#shutdown&lt;/code&gt; method. The tests pass again.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/rossta/loves-enumerable/commit/1d1cbc808a536a449b8f6dab5b9d4e0cb037f99c"&gt;Source for this changeset&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Adding Pooling&lt;/h3&gt;

&lt;p&gt;While we&amp;rsquo;ve achieved concurrency, you may notice there&amp;rsquo;s (at least) one problem.&lt;/p&gt;

&lt;p&gt;Our current implementation will naively create a new thread for each scheduled
job. This may not be an issue for small, trivial use cases, but it can be easily
abused. Thread creation does not come for free; every OS has its limit.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll prove it with our next test in which we&amp;rsquo;ll schedule a large number of
jobs.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def test_pool_size_limit
  pool_size = 5
  pool = ThreadPool.new(size: pool_size)
  mutex = Mutex.new
  threads = Set.new

  100_000.times do
    pool.schedule do
      mutex.synchronize do
        threads &amp;lt;&amp;lt; Thread.current
      end
    end
  end
  pool.shutdown

  assert_equal(pool_size, threads.size)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Running these tests on my mid-2014 MacBook Pro, I hit the resource limit:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TestThreadPool#test_pool_size_limit:
ThreadError: can&amp;#39;t create Thread: Resource temporarily unavailable
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `initialize&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `new&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:53:in `block in test_pool_size_limit&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:52:in `times&amp;#39;
    /Users/ross/dev/rossta/enumerable/examples/thread_pool/thread_pool_test.rb:52:in `test_pool_size_limit&amp;#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is now the whole point of our &lt;code&gt;ThreadPool&lt;/code&gt;, to limit the number of threads
in use. To implement this behavior, instead of executing the scheduled job in a
new thread, we&amp;rsquo;ll add them to a &lt;code&gt;Queue&lt;/code&gt;. We&amp;rsquo;ll separately create a
limited number of threads whose responsibility will be to pop new &amp;ldquo;jobs&amp;rdquo; off the
queue and execute them when available.&lt;/p&gt;

&lt;p&gt;The beauty of &lt;code&gt;Queue&lt;/code&gt; is that it is thread-safe; multiple threads in the thread pool an access this resource without corrupting its contents.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the revised implementation:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ThreadPool
  def initialize(size:)
    @size = size
    @jobs = Queue.new
    @pool = Array.new(size) do
      Thread.new do
        catch(:exit) do
          loop do
            job, args = @jobs.pop
            job.call(*args)
          end
        end
      end
    end
  end

  def schedule(*args, &amp;amp;block)
    @jobs &amp;lt;&amp;lt; [block, args]
  end

  def shutdown
    @size.times do
      schedule { throw :exit }
    end

    @pool.map(&amp;amp;:join)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s start with the &lt;code&gt;#schedule&lt;/code&gt; method. Where before we immediately creating a
new thread to call the block, we instead push the block and arguments onto the
new &lt;code&gt;@jobs&lt;/code&gt; queue instance variable.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def schedule(*args, &amp;amp;block)
  @jobs &amp;lt;&amp;lt; [block, args]
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This instance variable is setup in the &lt;code&gt;#initialize&lt;/code&gt; method where we also
eagerly create the maximum number of threads that will become our worker &lt;code&gt;@pool&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def initialize(size:)
  @size = size
  @jobs = Queue.new
  @pool = Array.new(size) do
    Thread.new do
      catch(:exit) do
        loop do
          job, args = @jobs.pop
          job.call(*args)
        end
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each thread runs an infinite loop that repeatedly pops jobs of the queue with
&lt;code&gt;@jobs.pop&lt;/code&gt;. The &lt;a href="http://ruby-doc.org/stdlib-2.0.0/libdoc/thread/rdoc/Queue.html#method-i-pop"&gt;&lt;code&gt;Queue#pop&lt;/code&gt;&lt;/a&gt; method here will block when the queue is empty so the thread will happily wait for new jobs to be scheduled at this point.&lt;/p&gt;

&lt;p&gt;Notice also to &lt;a href="http://ruby-doc.org/core-2.3.0/Kernel.html#method-i-catch"&gt;&lt;code&gt;catch&lt;/code&gt;&lt;/a&gt; block. We break out of the thread loops by
pushing &lt;code&gt;throw :exit&lt;/code&gt; on to the job queue, once for each thread in the
&lt;code&gt;#shutdown&lt;/code&gt; method. This means that jobs currently executing when the shutdown
method is called will be able to complete before the threads can be joined.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;def shutdown
  @size.times do
    schedule { throw :exit }
  end

  @pool.map(&amp;amp;:join)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a simple abstraction for handing concurrent work across a limited
number of threads. For more on this implementation, check out the original author&amp;rsquo;s &lt;a href="http://www.burgestrand.se/articles/quick-and-simple-ruby-thread-pool.html"&gt;blog post on
the subject&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/rossta/loves-enumerable/commit/cd6e89328948b9fd7e902764947163e4dd16b73d"&gt;Source for this changeset&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;In the Wild&lt;/h3&gt;

&lt;p&gt;Of course, if you&amp;rsquo;re planning on using a thread pool in production code, you&amp;rsquo;ll
may be better off leveraging the hard work of others. Our implementation omits
some key considerations, like providing reflection, handing timeouts, dealing with
exceptions, and better thread safety. Let&amp;rsquo;s look at some alternatives in the
community.&lt;/p&gt;

&lt;p&gt;The &lt;a href="https://github.com/meh/ruby-thread"&gt;ruby-thread&lt;/a&gt; project provides a few extensions to the standard library &lt;code&gt;Thread&lt;/code&gt; class, including &lt;code&gt;Thread::Pool&lt;/code&gt;. Usage of &lt;code&gt;Thread::Pool&lt;/code&gt; is very similar to what we came up with on the surface.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;thread/pool&amp;#39;

pool = Thread.pool(4)

10.times {
  pool.process {
    sleep 2

    puts &amp;#39;lol&amp;#39;
  }
}

pool.shutdown
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This implementation goes farther to ensure standard locking functions to work
properly across multiple Ruby implementations. Among other things, it has
support for handling timeouts, methods for introspecting pool objects, like
&lt;code&gt;#running?&lt;/code&gt; and &lt;code&gt;#terminated?&lt;/code&gt;, and optimizations for dealing with unused
threads. On reading the source, my impression is the implementation was heavily inspired by &lt;a href="https://github.com/puma/puma/blob/32b1fb3742e5918e0e79ee705b48c912a1f0742d/lib/puma/thread_pool.rb"&gt;Puma::ThreadPool&lt;/a&gt;, a class used internally by the puma web server. You be the judge.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/celluloid/celluloid"&gt;Celluloid&lt;/a&gt;, the most famous
collection of concurrency abstractions, provides a thread pool class,
most commonly accessed via a class method provided by the
&lt;code&gt;Celluloid&lt;/code&gt; mixin.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class MyWorker
  include Celluloid

  def add_one(number)
    # roflscale computation goes here
    number + 1
  end
end

MyWorker.pool

pool.future(:add_one, 5).value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The new hotness for working with concurrency is the toolkit provided by &lt;a href="https://github.com/ruby-concurrency/concurrent-ruby"&gt;concurrent-ruby&lt;/a&gt;. While &lt;code&gt;Celluloid&lt;/code&gt; is easy to get started with, &lt;code&gt;Concurrent&lt;/code&gt; is the &amp;ldquo;Swiss Army Knife&amp;rdquo;, providing a large array of abstractions and classes, including futures, promises, thread-safe collections, maybes, and so on. &lt;code&gt;Concurrent&lt;/code&gt; provides several different thread pool implementations for different purposes, each supporting a number of configurations, including min and max pool sizes, advanced shutdown behaviors, max queue size (along with a fallback policy when the job queue size is exceeded) to name a few.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;pool = Concurrent::FixedThreadPool.new(5) # 5 threads
pool.post do
  # some parallel work
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Consider the &lt;a href="http://ruby-concurrency.github.io/concurrent-ruby/file.thread_pools.html"&gt;Thread Pool&lt;/a&gt; overview provided in the &lt;code&gt;Concurrent&lt;/code&gt; docs required reading.&lt;/p&gt;

&lt;p&gt;And, of course, the ultimate thread pool for Rails developers is &lt;a href="https://github.com/mperham/sidekiq"&gt;Sidekiq&lt;/a&gt;. Unlike the examples we&amp;rsquo;ve discussed so far, the components of the Sidekiq thread pool model are distributed: the caller, the job queue, and the threaded workers all run in separate processes, often on separate machines, in a production environment.&lt;/p&gt;

&lt;h3&gt;Credits&lt;/h3&gt;

&lt;p&gt;In preparing for this post, I read through the source of several thread pool
implementations from various sources, ranging from simple examples, to internal
interfaces, to public-facing libraries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.burgestrand.se/code/ruby-thread-pool/"&gt;A simple, annotated thread pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/meh/ruby-thread/blob/f25dd1184f4f4bee7cde0d54ad5ce5e32dc15279/lib/thread/pool.rb"&gt;&lt;code&gt;Thread::Pool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/celluloid/celluloid/blob/c54bbde76e6a71b44c3ca6d1abf71197c64d7614/lib/celluloid/group/pool.rb"&gt;&lt;code&gt;Celluloid::Group::Pool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ruby-concurrency/concurrent-ruby/blob/536478817a3d0440f00ac09098f3ba71f0d8ce7c/lib/concurrent/executor/ruby_thread_pool_executor.rb"&gt;&lt;code&gt;Concurrent::RubyThreadPoolExecutor&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/puma/puma/blob/32b1fb3742e5918e0e79ee705b48c912a1f0742d/lib/puma/thread_pool.rb"&gt;&lt;code&gt;Puma::ThreadPool&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Though it&amp;rsquo;s well documented how much &lt;a href="http://adam.herokuapp.com/past/2009/8/13/threads_suck/"&gt;threads suck&lt;/a&gt;, that shouldn&amp;rsquo;t discourage Rubyists from trying to get some first-hand experience with working with threads, supporting classes from the standard library like &lt;code&gt;Queue&lt;/code&gt;, &lt;code&gt;Mutex&lt;/code&gt;, and &lt;code&gt;ConditionVariable&lt;/code&gt; and generic abstractions like &lt;code&gt;ThreadPool&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Connection Pool, the Sequel&lt;/h3&gt;

&lt;p&gt;Related, though not necessarily thread-based, is the concept of a connection
pool, which limits the number of network connections to a particular service.
You&amp;rsquo;ll find connection pools in &lt;a href="https://github.com/rails/rails/blob/107f4282bbfabc011d5ad3bcf3fb3c6fb812ad30/activerecord/lib/active_record/connection_adapters/abstract/connection_pool.rb"&gt;activerecord&lt;/a&gt;, &lt;a href="https://github.com/mongodb/mongo-ruby-driver/blob/eece2a769bbf1a302b2f70b23dc6a43490392979/lib/mongo/server/connection_pool.rb"&gt;mongodb&lt;/a&gt;, and, as a standalone
abstraction in the approrpriately-named,
&lt;a href="https://github.com/mperham/connection_pool"&gt;connection_pool&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s good to know
about connection pools for setting a connection to Redis from your Ruby
applications with the &lt;a href="https://github.com/redis/redis-rb"&gt;redis-rb&lt;/a&gt; gem. As of this writing, this client does not manage a connection pool for you, so &lt;a href="http://www.blrice.net/blog/2015/04/24/take-a-swim-in-the-connection-pool/"&gt;the common gotcha&lt;/a&gt; is a memory-leak that originates from creating a lot of open connections to the Redis server. You can avoid this with &lt;code&gt;ConnectionPool&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;redis = ConnectionPool.new { Redis.new }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much like &lt;code&gt;ThreadPool&lt;/code&gt;, having at least a cursory understanding of what&amp;rsquo;s happening
underneath can help you avoid issues with managing resources like network
connections.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>What I learned building an app in Hanami</title>
    <link rel="alternate" href="/blog/what-i-learned-about-hanami.html"/>
    <id>/blog/what-i-learned-about-hanami.html</id>
    <published>2016-02-21T19:00:00-05:00</published>
    <updated>2016-02-21T19:00:00-05:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;For the past year, I’ve been loosely following the progress on &lt;a href="http://hanamirb.org"&gt;Hanami&lt;/a&gt; (formerly Lotus), a new web framework
for Ruby created by &lt;a href="https://github.com/jodosha"&gt;Luca Guidi (@jodosha)&lt;/a&gt;. I recently decided to build a small app in Hanami to get a feel for its design and to understand...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;For the past year, I&amp;rsquo;ve been loosely following the progress on &lt;a href="http://hanamirb.org"&gt;Hanami&lt;/a&gt; (formerly Lotus), a new web framework
for Ruby created by &lt;a href="https://github.com/jodosha"&gt;Luca Guidi (@jodosha)&lt;/a&gt;. I recently decided to build a small app in Hanami to get a feel for its design and to understand better its fresh perspective on web development in Ruby. In other words, to answer for myself, &amp;ldquo;Is Hanami better than Rails?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://github.com/rossta/github_groove"&gt;The app&lt;/a&gt; is a simple integration between GitHub issues and the helpdesk platform, &lt;a href="https://www.groovehq.com"&gt;Groove&lt;/a&gt;.
Visitors can login via OAuth through their GitHub accounts, connect to a Groove
account with an API key, import their Groove tickets, and create GitHub issues
from these tickets through the app. You can see the &lt;a href="https://github.com/rossta/github_groove"&gt;source on Github&lt;/a&gt; and play with the &lt;a href="https://github-groove.herokuapp.com/"&gt;app hosted on Heroku&lt;/a&gt;, where it would help to have accounts on both GitHub and Groove to see how it works.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve made note of what I learned and some of the challenges I faced while going beyond the &lt;a href="http://hanamirb.org/guides/"&gt;getting
started guides&lt;/a&gt; to build and deploy the app. This post is not an introduction
to Hanami - the &lt;a href="http://hanamirb.org/guides/"&gt;guides&lt;/a&gt; serve as an excellent overview.&lt;/p&gt;

&lt;aside class="callout panel"&gt;
  &lt;p&gt;The Github-Groove app is built on &lt;code&gt;hanami-0.7.0&lt;/code&gt;. As the framework is under
heavy development (as of this writing the latest version is
&lt;code&gt;v0.7.2&lt;/code&gt;), your experience getting started with Hanami may differ.
  &lt;/p&gt;
&lt;/aside&gt;

&lt;h3&gt;Hanami opinions are not Rails opinions&lt;/h3&gt;

&lt;p&gt;Hanami has a lot in common with Rails. Both are web frameworks built on Ruby
that employ some version of the Model-View-Controller pattern and, among other
things, value &lt;a href="http://rubyonrails.org/doctrine/#convention-over-configuration"&gt;convention over configuration&lt;/a&gt;.
Both frameworks are &lt;em&gt;opinionated&lt;/em&gt; about how web apps should be built. In a
nutshell, Hanami takes what it likes from Rails and draws the line on certain
principles including avoidance of monkey-patching, enforcing modularity, and encouraging
the use of &amp;ldquo;plain old Ruby objects&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re coming from Rails, you can expect to learn some new conventions in Hanami.
&lt;a href="http://hanamirb.org/guides/getting-started/"&gt;As the guides warn&lt;/a&gt;,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;learning these conventions may be hard: without change, there is no challenge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The framework pushes you toward &amp;ldquo;monolith first&amp;rdquo; while emphasizing &amp;ldquo;separation of concerns&amp;rdquo;. There are suggestions in the generated directory structure like how the &lt;code&gt;app/&lt;/code&gt; folder is named &lt;code&gt;apps/&lt;/code&gt; in Hanami encouraging you from the start to define sub-applications boundaries under one umbrella, or &amp;ldquo;container&amp;rdquo; in Hanami parlance. So while in Rails has engines as an opt-in feature, you build everything as an engine in Hanami. Each &amp;ldquo;app&amp;rdquo; gets its own set of views, controllers, assets, configuration, etc. Shared resources, like models, tend to go in &lt;code&gt;lib/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You also get useful development tools like generators, migrations, and asset
pipelines in Hanami, but expect less ceremony here. Migrations handed off to the
venerable &lt;a href="http://sequel.jeremyevans.net/rdoc/files/doc/schema_modification_rdoc.html"&gt;Sequel&lt;/a&gt; project and the asset story is still young but passable; you won&amp;rsquo;t be able to take advantage of the multitude of Rails-asset gems.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d be interested to see Hanami go in a different direction here, like taking advantage of the &amp;ldquo;frontend explosion&amp;rdquo; by providing integration with external pipelines as the static-site generator &lt;a href="https://middlemanapp.com/advanced/external-pipeline/"&gt;middleman has done&lt;/a&gt; or what &lt;a href="http://www.shakacode.com/"&gt;Shakacode&lt;/a&gt; is trying with &lt;a href="https://webpack.github.io/"&gt;webpack&lt;/a&gt; in &lt;a href="https://github.com/shakacode/react_on_rails"&gt;&lt;code&gt;react_on_rails&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that Hanami comes with security features baked in for as one would expect, including &lt;a href="https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)"&gt;CSRF protection&lt;/a&gt; and app-level secure-by-default options for items like &lt;a href="https://developer.mozilla.org/en-US/docs/Web/Security/CSP"&gt;Content Security Policy&lt;/a&gt; and &lt;code&gt;X-Frame-Options&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One gotcha is that Hanami &lt;a href="https://github.com/hanami/hanami/issues/249"&gt;does not itself provide any mechanism for code
reloading&lt;/a&gt; (at the moment). This
was not obvious to me starting off since the development server does &amp;ldquo;appear&amp;rdquo; to reload code. It turns out that the dev server launches with &lt;a href="https://github.com/rtomayko/shotgun"&gt;Shotgun&lt;/a&gt; (commonly used in Sinatra projects), to serve each development request in a new process with &lt;code&gt;fork(2)&lt;/code&gt;. I didn&amp;rsquo;t pick up on this until several iterations in when I added the &lt;a href="https://github.com/brandonhilkert/sucker_punch"&gt;SuckerPunch gem&lt;/a&gt; and couldn&amp;rsquo;t figure out why my background jobs wouldn&amp;rsquo;t run in development. I added a &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/apps/web/controllers/tickets/sync.rb#L11"&gt;sync action&lt;/a&gt; that allows users to trigger a &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/lib/github_groove/jobs/sync_tickets_job.rb"&gt;background job to import ticket data&lt;/a&gt; from Groove into the application. Long story short, kicking off background jobs in threads in the request process, as is possible with SuckerPunch, won&amp;rsquo;t work without disabling Shotgun.&lt;/p&gt;

&lt;h3&gt;Hanami MVC is not Rails MVC&lt;/h3&gt;

&lt;p&gt;With the Model-View-Controller paradigm, you&amp;rsquo;ll see some big departures from
Rails. First, controllers are not classes with &amp;ldquo;RESTful&amp;rdquo; methods, but
&lt;em&gt;directories&lt;/em&gt; of related action classes. In other words, instead of defining
&lt;code&gt;#index&lt;/code&gt;, &lt;code&gt;#show&lt;/code&gt;, &lt;code&gt;#create&lt;/code&gt;, etc. in a &lt;code&gt;PostsController&lt;/code&gt;, you create a separate
class for each action using a mixin that live in a directory that would
represent a single controller in Rails.&lt;/p&gt;

&lt;p&gt;In my Github-Groove app, here&amp;rsquo;s how I organize the tickets controller:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sh"&gt;app/
  web/
    assets/
    config/
    controllers/
      tickets/
        index.rb
        show.rb
        sync.rb
    templates/
    views/
    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each &amp;ldquo;action&amp;rdquo; is a Rack-inspired class whose contract is only that it responds to &lt;code&gt;#call&lt;/code&gt;. You still get
familiar macros like &lt;code&gt;before&lt;/code&gt; filters, but there are new ideas too, like declaring what instance variables are available to the view with &lt;code&gt;expose&lt;/code&gt;, inserting action-specific middleware, and whitelisting &lt;code&gt;params&lt;/code&gt; at the class level, all of which I find to be huge improvements over the Rails controller design.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;module Web::Controllers::Project
  class Create
    include Web::Action

    expose :project
    before :authenticate!

    params do
      param :project do
        param :groove_access_token, presence: true
        param :github_repository, presence: true
      end
    end

    def call(params)
      if params.valid?
        @project = ProjectRepository.find_or_create_by_params(params[:project])
        UserRepository.update_user_project(current_user, @project)

        flash[:notice] = &amp;quot;Your project has been saved!&amp;quot;

        redirect_to &amp;quot;/project&amp;quot;
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Arguably, the biggest efforts in Hanami appear to be at this action layer and it
shows in the &lt;a href="http://hanamirb.org/guides/actions/overview/"&gt;guides&lt;/a&gt; and the
&lt;a href="https://github.com/hanami/controller/blob/master/README.md"&gt;README&lt;/a&gt; where you
can find a ton of great information for customizing these classes.&lt;/p&gt;

&lt;p&gt;Another big benefit in the controller design, and for most of the Hanami
framework, is that unit-testing has a much lower barrier to entry. To get
controller tests to work in Rails requires a ton of setup behind the scenes to
the point where you essentially have integration tests. Controllers tests in
Hanami are much simpler by the simple fact that getting a testable object is as
easy as &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/spec/web/controllers/project/create_spec.rb#L5"&gt;instantiating a Hanami action&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In Hanami, &amp;ldquo;views&amp;rdquo; are classes that act more like presenter to represent a model
or collection of models for the &amp;ldquo;templates&amp;rdquo;, which the place of the
&lt;code&gt;views/&lt;/code&gt; folder in Rails. Like Rails, file-naming conventions link an action,
view, and template. The helper method story is still developing, but you can
expect to find some surprises in the docs, like the criticism of Rails
monkey-patching of ERB to achieve block-style helpers for things like forms.
Expect to get tripped up by these differences in helper syntax which ironically are
valid ERB. Hanami does support all the other popular templating engines through
&lt;a href="https://github.com/rtomayko/tilt"&gt;Tilt&lt;/a&gt; for your preference.&lt;/p&gt;

&lt;p&gt;Hanami also provides &lt;code&gt;hanami-model&lt;/code&gt; for the model layer as a soft-dependency so
you can bring your own ORM if desired. If you choose to use &lt;code&gt;hanami-model&lt;/code&gt; as I
did, you can expect to leave your ActiveRecord convenience (and baggage) behind.
Hanami&amp;rsquo;s model layer emulates the &lt;a href="http://martinfowler.com/eaaCatalog/repository.html"&gt;repository pattern&lt;/a&gt; where database queries, table mapping, and entities are all separate concerns.&lt;/p&gt;

&lt;p&gt;Repositories become a collection of query methods:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class ProjectRepository
  include Hanami::Repository

  def self.find_or_create_by_params(params)
    found = find_by_groove_access_token(params[:groove_access_token])

    if found
      found.update(params)
      update found
    else
      create(Project.new(params))
    end
  end

  def self.find_by_groove_access_token(groove_access_token)
    query do
      where(groove_access_token: groove_access_token)
    end.first
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Entities feel basically like POROS that provide a thin layer over attributes.
Don&amp;rsquo;t expect to find any database access, validations (by default anyhow), or callbacks here.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class Project
  include Hanami::Entity

  attributes :groove_access_token, :github_repository, :syncing

  def ready?
    groove_access_token.present? &amp;amp;&amp;amp; github_repository.present?
  end

  # ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Validations do exist in Hanami &lt;a href="https://github.com/hanami/validations"&gt;as a separate mixin&lt;/a&gt; but these are more typically done in the params macro at the action-layer.&lt;/p&gt;

&lt;h2&gt;Expect to write code&lt;/h2&gt;

&lt;p&gt;While Hanami has its own variety of &amp;ldquo;magic&amp;rdquo; of the kind that developers have come to
either love or hate in Rails, you can expect to write code you might not
otherwise have to in Rails. The framework is still young, so there are missing
features. What&amp;rsquo;s not always clear is whether these features have been left out
by priority or choice. To figure that out takes some digging on GitHub issues, the Hanami &lt;a href="https://gitter.im/hanami/chat"&gt;chat&lt;/a&gt; and &lt;a href="https://discuss.hanamirb.org/"&gt;Discourse forum&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Though its database layer has the &lt;a href="https://github.com/jeremyevans/sequel"&gt;Sequel&lt;/a&gt; library as a foundation, I didn&amp;rsquo;t find the repository and entity functionality as fully-developed. I found myself writing a lot of boilerplate code in the entities and repositories with a lot of co-dependence between the classes. With some more thoughtful design and refactoring, I could probably address this issue, but at this stage, the separation of concerns is less apparent: entities and repositories appear to be tightly bound. &lt;a href="https://github.com/hanami/model/issues/291"&gt;Convenience methods&lt;/a&gt; are still in the works.&lt;/p&gt;

&lt;p&gt;For one, &lt;a href="https://github.com/hanami/model/pull/244"&gt;associations&lt;/a&gt; are still in development at the time of this writing (see open issue &lt;a href="https://github.com/hanami/model/issues/35"&gt;here&lt;/a&gt;). Much of my entity code was to fill this gap - to load objects linked by foreign keys via repositories like below.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class Project
  include Hanami::Entity

  def tickets(params = {})
    TicketRepository.all_by_project(self, params)
  end
end

class TicketRepository
  include Hanami::Repository

  def self.all_by_project(project, _params = {})
    query do
      where(project_id: project.id).desc(:number)
    end.all
  end

  # ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m not sure if this is the &amp;ldquo;Hanami-way&amp;rdquo;, but I found myself doing this kind of
thing a lot.&lt;/p&gt;

&lt;p&gt;I also ran into some unexpected issues while deploying the application to Heroku
where its &lt;code&gt;HANAMI_ENV&lt;/code&gt; is set to &lt;code&gt;&amp;#39;production&amp;#39;&lt;/code&gt;. In many cases, custom classes I
extracted, like one for sharing &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/lib/github_groove/repositories/pagination.rb"&gt;a pagination query&lt;/a&gt; and another for &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/lib/github_groove/vendor/groove.rb"&gt;wrapping the &lt;code&gt;Groove API Ruby Client&lt;/code&gt;&lt;/a&gt; (my &lt;a href="https://github.com/Fodoj/groovehq/pull/16"&gt;fork with paginated enumeration&lt;/a&gt;) weren&amp;rsquo;t &amp;ldquo;autoloaded&amp;rdquo; when booting the Hanami application. To resolve this, I added explicit requires like &lt;code&gt;require_relative &amp;#39;./pagination&amp;#39;&lt;/code&gt;. Again, I didn&amp;rsquo;t have time to dig into whether this issue would be expected or not; I could have been missing something important here.&lt;/p&gt;

&lt;h3&gt;The Community is still young&lt;/h3&gt;

&lt;p&gt;That brings me to the community - it&amp;rsquo;s extremely supportive, but still very
small. I encountered a lot of helpful folks on
&lt;a href="https://gitter.im/hanami/chat"&gt;chat&lt;/a&gt; including &lt;code&gt;@jodosha&lt;/code&gt; himself, but there
simply hasn&amp;rsquo;t been enough traction to reach &lt;a href="https://stackoverflow.com/questions/tagged/hanami"&gt;StackOverflow&lt;/a&gt; critical mass where just about any question you can think of in Rails already has an answer.&lt;/p&gt;

&lt;p&gt;This means a lot more code-spelunking in the &lt;a href="https://github.com/hanami"&gt;hanami&lt;/a&gt; repositories. To that end, I found the code extremely clean, well-documented, and approachable whereas, even today, I need to brace myself before diving into Rails source.&lt;/p&gt;

&lt;p&gt;That said, you can expect to run into edge cases and bugs occasionally that may
not yet have a solution, including this &lt;a href="https://github.com/pry/pry/issues/1471#issuecomment-187420164"&gt;incredibly irksome&lt;/a&gt; issue that prevents you from accessing the pry console when using &lt;code&gt;binding.pry&lt;/code&gt; in Hanami controllers and the problem I mentioned earlier that prevents you from using SuckerPunch in development with Shotgun enabled.&lt;/p&gt;

&lt;p&gt;Another challenge is that all those Rails-specific plugins and engines
you&amp;rsquo;ve come to rely on won&amp;rsquo;t work in Hanami: Yikes, you have build authentication without Devise!
Using &lt;a href="https://github.com/hassox/warden"&gt;&lt;code&gt;Warden&lt;/code&gt;&lt;/a&gt;, the general Rack-based
authentication middleware on which Devise is based, is very feasible and you can always
rely on &lt;a href="https://github.com/rossta/github_groove/blob/4cb64e1a92013cf6eb56a3abd6678020640eaf5c/apps/web/application.rb#L86"&gt;OmniAuth like I did&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The lesson here is that with Hanami, you&amp;rsquo;re much more likely to have to &amp;ldquo;roll up
your sleeves&amp;rdquo; to get to the bottom of issues, figure how to do things that
aren&amp;rsquo;t covered by the guides, or otherwise, get from a Rails-specific gem.&lt;/p&gt;

&lt;h3&gt;Hanami is and is not Rails&lt;/h3&gt;

&lt;p&gt;So should you build your next app in Hanami? Only you can answer that of course.
The lightweight approach in Hanami means there is less to wrap your head around
if you&amp;rsquo;re coming from Rails, but there is still a learning curve nonetheless. I&amp;rsquo;d say it&amp;rsquo;s a worthwhile endeavor to build something small like I did at first to push the boundaries and answer the questions you have about Hanami for yourself.&lt;/p&gt;

&lt;p&gt;Hanami treads the same ground as Rails and aims to do a lot of the low level
work for you so can focus on what&amp;rsquo;s important - your business logic. Personally, I found a lot of advantages in the &amp;ldquo;Hanami way&amp;rdquo; and enjoyed the experience of the new paradigm. My &amp;ldquo;Rails muscle memory&amp;rdquo; tripped me up on occasion and left me pining for features that don&amp;rsquo;t exist or are not as well-developed in Hanami yet. I see a lot of potential in the Hanami framework and see it growing into a viable alternative to Rails in the near future.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href="https://github.com/rossta/github_groove"&gt;GitHub-Groove source&lt;/a&gt; and &lt;a href="https://github-groove.herokuapp.com/"&gt;demo app&lt;/a&gt; and let me know what I could have done differently.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Clojure's iterate in Ruby</title>
    <link rel="alternate" href="/blog/clojure-iterate-in-ruby.html"/>
    <id>/blog/clojure-iterate-in-ruby.html</id>
    <published>2016-02-16T19:00:00-05:00</published>
    <updated>2016-02-16T19:00:00-05:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;In functional languages, the key building blocks are functions and data. Clojure has a particularly interesting data structure, &lt;a href="http://clojure.org/sequences"&gt;sequences&lt;/a&gt;, not featured in the Ruby standard library. A Clojure sequence is an immutable collection that representing the...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;In functional languages, the key building blocks are functions and data. Clojure has a particularly interesting data structure, &lt;a href="http://clojure.org/sequences"&gt;sequences&lt;/a&gt;, not featured in the Ruby standard library. A Clojure sequence is an immutable collection that representing the result of an algorithm. Previously, I described how to generate Clojure-like &lt;a href="https://rossta.net/blog/pascals-triangle-with-rubys-enumerator.html"&gt;sequences in Ruby&lt;/a&gt; (without the immutability anyways), including &lt;a href="https://rossta.net/blog/infinite-sequences-in-ruby.html"&gt;Pascal&amp;rsquo;s Triangle&lt;/a&gt; using &lt;code&gt;Enumerator&lt;/code&gt;, which allows us to package up an algorithm as an object that can emit values as any &amp;ldquo;eager&amp;rdquo; collection can, like &lt;code&gt;Array&lt;/code&gt; and &lt;code&gt;Hash&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Clojure provides a few functions that can be used to generate sequences,
including &lt;code&gt;iterate&lt;/code&gt;. According to the &lt;a href="https://clojuredocs.org/clojure.core/iterate"&gt;docs&lt;/a&gt;,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Returns a lazy sequence of x, (f x), (f (f x)) etc. f must be free of side-effects&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, &lt;code&gt;iterate&lt;/code&gt; will emit values starting with the first and repeatedly call the given function with the return value of the previous call.&lt;/p&gt;

&lt;p&gt;The signature in Clojure looks this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="clojure"&gt;(iterate f x)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, we can generate a simple sequence of numbers using the &lt;code&gt;inc&lt;/code&gt; function and some start value:&lt;/p&gt;

&lt;pre&gt;&lt;code class="clojure"&gt;=&amp;gt; (iterate inc 1)
(1 2 3 4 5 ...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, we have a terse was of generating a sequence like this in Ruby:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;irb(main)&amp;gt; (1..5).to_a
=&amp;gt; [1, 2, 3, 4, 5]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But this solution doesn&amp;rsquo;t generalize to other types of sequences like, for instance,
generating a sequence of the powers of 2. In the example below, &lt;code&gt;(partial * 2)&lt;/code&gt;
returns a function that multiplies a single argument by 2.&lt;/p&gt;

&lt;pre&gt;&lt;code class="clojure"&gt;=&amp;gt; (iterate (partial * 2) 1)
(1 2 4 8 16 32 64 128 ...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get this result in Ruby, we might try something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;irb&amp;gt; (1..7).each_with_object([]) { |n, seq| seq &amp;lt;&amp;lt; (seq.last.nil? ? n : seq.last * 2) }
=&amp;gt; [1, 2, 4, 8, 16, 32, 64]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not very pretty (ok, I admit that&amp;rsquo;s a strawman). But this also is an &amp;ldquo;eagerly&amp;rdquo;
generated collection whereas we want something that can be lazily generated to
get closer to Clojure.&lt;/p&gt;

&lt;p&gt;While there may be a number of ways to generate these sequences in Ruby, for this
exercise, we also want something that has a similar signature to Clojure&amp;rsquo;s &lt;code&gt;iterate&lt;/code&gt;,
like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;iterate(x, &amp;amp;block)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll leverage Ruby&amp;rsquo;s method block convention in place of the function, &lt;code&gt;f&lt;/code&gt;.
Usage:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;irb&amp;gt; iterate(1) { |n| n + 1 }
=&amp;gt; [1, 2, 3, 4, 5, ...]
irb&amp;gt; iterate(1) { |n| n * 2 }
=&amp;gt; [1, 2, 4, 8, 16, 32, 64, ...]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The two examples now have the same &amp;ldquo;surface area&amp;rdquo; and have a lot in common with the Clojure
companions. So how would we implement this?&lt;/p&gt;

&lt;p&gt;First a test. By the way, all the code found in the following examples is &lt;a href="https://github.com/rossta/loves-enumerable/tree/master/examples/sequence"&gt;on Github&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;minitest/autorun&amp;#39;
require_relative &amp;#39;./sequence&amp;#39;

class TestSequence &amp;lt; Minitest::Test
  include Sequence

  def test_iterate_increment
    sequence = iterate(1) { |x| x + 1 }

    assert_equal sequence.first(5), [1, 2, 3, 4, 5]
  end

  def test_iterate_power_of_2
    sequence = iterate(1) { |x| x * 2 }

    assert_equal sequence.first(5), [1, 2, 4, 8, 16]
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re going to implement &lt;code&gt;iterate&lt;/code&gt; in a Ruby module called &lt;code&gt;Sequence&lt;/code&gt;. Our test
for &lt;code&gt;iterate&lt;/code&gt; will return an instance of &lt;code&gt;Enumerator&lt;/code&gt; (the &lt;code&gt;sequence&lt;/code&gt; variable).
The enumerator allows use to generate the sequence on demand with the call to
&lt;code&gt;#first&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the implementation:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;module Sequence
  def iterate(arg)
    Enumerator.new do |yielder|
      current = arg
      loop do
        yielder &amp;lt;&amp;lt; current
        current = yield(current)
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our implementation of &lt;code&gt;iterate&lt;/code&gt; returns an &lt;code&gt;Enumerator&lt;/code&gt; that will first yield
the given &lt;code&gt;arg&lt;/code&gt; and repeatedly call the given block with the result of the
previous call. The &lt;code&gt;loop&lt;/code&gt; construct means this enumeration can potentially
continue forever - capturing the spirit of a Clojure sequence. That means
we need to use a terminating functions like &lt;code&gt;#first&lt;/code&gt; or &lt;code&gt;#take&lt;/code&gt; to limit the
results, just like we would in Clojure:&lt;/p&gt;

&lt;pre&gt;&lt;code class="clojure"&gt;=&amp;gt; (take 5 (iterate (partial * 2) 1))
(1 2 4 8 16)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Ruby equivalent:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;iterate(1) { |n| n * 2 }.take(5)
=&amp;gt; [1, 2, 4, 8, 16]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We could go one step further an make this method work as a mixin. Below is a
test for using &lt;code&gt;iterate&lt;/code&gt; as an instance method of a class using in our tests
that will simply delegate missing methods to the object passed in on
instantiation.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class TestSequence &amp;lt; Minitest::Test
  include Sequence

  class Sequenced &amp;lt; SimpleDelegator
    include Sequence
  end

  def test_iterate_include
    num = Sequenced.new(0)

    sequence = num.iterate { |x| x - 1 }
    assert_equal sequence.first(5), [0, -1, -2, -3, -4]
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make this pass, we need only set the default arg to &lt;code&gt;self&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;module Sequence
  def iterate(arg = self)
    # ...
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what? Ok, well, you may be hard pressed to use &lt;code&gt;iterate&lt;/code&gt; in your daily work,
but there is certainly more room to think about data processing as functional
operations (free of side effects) on sequences (values that can be generated on demand). Something like &lt;code&gt;iterate&lt;/code&gt; need not apply to only numbers; you can imagine sequences of letters, time objects, or POROs also being generated. At times, Rubyist are too quick to wrap collections in other classes when simpler, more generalizable &amp;ldquo;functional&amp;rdquo; transforms could suffice.&lt;/p&gt;

&lt;p&gt;When I started &lt;a href="http://devpost.com/software/learning-clojure"&gt;learning Clojure&lt;/a&gt; last year, I got really excited about the functional aspects of Ruby. &amp;ldquo;Wait, I thought everything in Ruby is an object.&amp;rdquo; Yes, but a great thing about Ruby is its &lt;a href="http://yehudakatz.com/2009/07/11/python-decorators-in-ruby/"&gt;ability to adopt aspects of other languages&lt;/a&gt;. As Piotr Solnica illustrates in &lt;a href="https://speakerdeck.com/solnic/blending-functional-and-oo-programming-in-ruby"&gt;his recent talk&lt;/a&gt;, blending functional techniques with our OO code can have a lot of benefits including avoidance of side effects and favoring composability. Introducing sequence-generating methods, like we saw here, is just one small idea to help sprinkle a little functional flavor into your Ruby code.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Recurring events in Ruby</title>
    <link rel="alternate" href="/blog/recurring-events-in-ruby.html"/>
    <id>/blog/recurring-events-in-ruby.html</id>
    <published>2016-02-02T19:00:00-05:00</published>
    <updated>2016-02-02T19:00:00-05:00</updated>
    <author>
      <name>Ross Kaffenberger</name>
    </author>
    <summary type="html">&lt;p&gt;&lt;img alt="How many more times?" src="/assets/images/blog/stock/clock-pexels-photo-160981e8.jpg"&gt;&lt;/p&gt;

&lt;p&gt;I was considering recently how I’d build an &lt;a href="http://meetedgar.com/"&gt;Edgar&lt;/a&gt; clone to post updates about &lt;a href="/"&gt;rossta.net&lt;/a&gt; on Twitter and LinkedIn at recurring intervals, for example, every Tuesday at 9AM EST.&lt;/p&gt;

&lt;p&gt;For scheduling tasks, we have &lt;a href="http://www.unixgeeks.org/security/newbie/unix/cron-1.html"&gt;cron&lt;/a&gt; at the system level and even such...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;&lt;img alt="How many more times?" src="/assets/images/blog/stock/clock-pexels-photo-160981e8.jpg" /&gt;&lt;/p&gt;

&lt;p&gt;I was considering recently how I&amp;rsquo;d build an &lt;a href="http://meetedgar.com/"&gt;Edgar&lt;/a&gt; clone to post updates about &lt;a href="/"&gt;rossta.net&lt;/a&gt; on Twitter and LinkedIn at recurring intervals, for example, every Tuesday at 9AM EST.&lt;/p&gt;

&lt;p&gt;For scheduling tasks, we have &lt;a href="http://www.unixgeeks.org/security/newbie/unix/cron-1.html"&gt;cron&lt;/a&gt; at the system level and even such options as the &lt;a href="https://github.com/javan/whenever"&gt;&lt;code&gt;whenever&lt;/code&gt;&lt;/a&gt; gem to setup cron from Rails and Sinatra applications. Rubyists can also take advantage of fantastic background job schedulers like &lt;a href="https://github.com/jmettraux/rufus-scheduler"&gt;&lt;code&gt;rufus-scheduler&lt;/code&gt;&lt;/a&gt; to run recurring tasks from a separate process or even an API for defining repeating &lt;a href="https://github.com/mperham/sidekiq"&gt;&lt;code&gt;Sidekiq&lt;/code&gt;&lt;/a&gt; jobs with &lt;a href="https://github.com/tobiassvn/sidetiq"&gt;&lt;code&gt;Sidetiq&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For an Edgar clone though, we need a layer for users of the application to define their own recurrences. This means finding a way to represent time-based recurrences which are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;serializable, so we can save them to the database, and&lt;/li&gt;
&lt;li&gt;enumerable, so we can determine when the next post(s) should be shared on designated social networks.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It&amp;rsquo;s an interesting problem to model. While we have classes like &lt;code&gt;Time&lt;/code&gt;, &lt;code&gt;Date&lt;/code&gt;, and event &lt;code&gt;ActiveSupport::Duration&lt;/code&gt;, it&amp;rsquo;s more elusive to consider recurrences. I mean, what does it mean to represent the meeting time of my &lt;a href="http://www.meetup.com/NYC-rb/"&gt;NYC.rb&lt;/a&gt; meetup: &amp;ldquo;every second Tuesday of the month at 7pm&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Solutions for this exist in Ruby, namely &lt;a href="https://github.com/seejohnrun/ice_cube"&gt;&lt;code&gt;ice_cube&lt;/code&gt;&lt;/a&gt;. If you&amp;rsquo;re looking for a mature, up-to-date project devoted to modeling recurring events in Ruby, please check it out. I did, and highly recommend it. After playing with it for awhile, I found felt the urge for alternative semantics - like the ability to define a recurrence without a start date - and API similar to the hash-like syntax provided by another less-active recurring events library, &lt;a href="https://github.com/fnando/recurrence"&gt;&lt;code&gt;recurrence&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I thought of the &lt;a href="https://github.com/httprb/http"&gt;&lt;code&gt;HTTP&lt;/code&gt;&lt;/a&gt; gem which bills
itself as the following:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;HTTP (The Gem! a.k.a. http.rb) is an easy-to-use client library for making requests from Ruby. It uses a simple method chaining system for building requests, similar to Python&amp;rsquo;s &lt;a href="http://docs.python-requests.org/en/latest/"&gt;Requests&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Taking a cue from &lt;code&gt;http.rb&lt;/code&gt; and the &lt;code&gt;recurrence&lt;/code&gt; gem, I set out to create something similar for recurring events.&lt;/p&gt;

&lt;p&gt;Introducing &lt;a href="https://github.com/rossta/montrose"&gt;&lt;code&gt;Montrose&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Montrose allows you to easily create &amp;ldquo;recurrence&amp;rdquo; objects through chaining:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every Monday at 10:30am
Montrose.weekly.on(:monday).at(&amp;quot;10:30 am&amp;quot;)
=&amp;gt; #&amp;lt;Montrose::Recurrence...&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or the constructor hash-syntax:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;Montrose::Recurrence.new(every: :week, on: :monday, at: &amp;quot;10:30 am&amp;quot;)
=&amp;gt; #&amp;lt;Montrose::Recurrence...&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A Montrose recurrence responds to &lt;code&gt;#events&lt;/code&gt;, which returns an &lt;a href="/blog/what-is-enumerator.html"&gt;&lt;code&gt;Enumerator&lt;/code&gt;&lt;/a&gt; that can generate timestamps:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;r = Montrose.hourly
=&amp;gt; #&amp;lt;Montrose::Recurrence...&amp;gt;

r.events
=&amp;gt; #&amp;lt;Enumerator:...&amp;gt;

r.events.take(10)
=&amp;gt; [2016-02-03 18:26:08 -0500,
2016-02-03 19:26:08 -0500,
2016-02-03 20:26:08 -0500,
2016-02-03 21:26:08 -0500,
2016-02-03 22:26:08 -0500,
2016-02-03 23:26:08 -0500,
2016-02-04 00:26:08 -0500,
2016-02-04 01:26:08 -0500,
2016-02-04 02:26:08 -0500,
2016-02-04 03:26:08 -0500]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Montrose recurrences are themselves enumerable:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every month starting a year from now on Friday the 13th for 5 occurrences
r = Montrose.monthly.starting(1.year.from_now).on(friday: 13).repeat(5)

r.map(&amp;amp;:to_date)
=&amp;gt; [Fri, 13 Oct 2017,
Fri, 13 Apr 2018,
Fri, 13 Jul 2018,
Fri, 13 Sep 2019,
Fri, 13 Dec 2019]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each chained recurrence returns a new object so they can be composed and
merged:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every week
r1 = Montrose.every(:week)
r2 = Montrose.on([:tuesday, :thursday])
r3 = Montrose.at(&amp;quot;12 pm&amp;quot;)
r4 = Montrose.total(4)

r1.merge(r2).merge(r3).merge(r4).to_a
=&amp;gt; [2016-02-04 12:00:00 -0500,
2016-02-09 12:00:00 -0500,
2016-02-11 12:00:00 -0500,
2016-02-16 12:00:00 -0500]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With a nod to DHH and the &lt;a href="http://rubyonrails.org/doctrine"&gt;Rails doctrine&lt;/a&gt;, Montrose aims to &lt;a href="http://rubyonrails.org/doctrine/#optimize-for-programmer-happiness"&gt;optimize for programmer happiness&lt;/a&gt;. Hence, there are several ways to define equivalent recurrences. For example, recurrences intervals can be configured as an explicit option, or inferred by the frequency duration.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every 3 hours, all equivalent
Montrose.hourly.interval(3)
Montrose.every(3.hours)
Montrose::Recurrence.new(every: :hour, interval: 3)
Montrose::Recurrence.new(every: 3.hours)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Montrose&lt;/code&gt; tries to provide useful feedback when you run into exceptions:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;r = Montrose.total(1)
r.each { |t| puts t}
Montrose::ConfigurationError: Please specify the :every option
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Conceptually, recurrences can represent an infinite sequence. When we say
simply &amp;ldquo;every day&amp;rdquo;, there is no implied ending. It&amp;rsquo;s therefore possible to
create a recurrence that can enumerate forever.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every day starting now
r = Montrose.daily

# this expression will never complete, Ctrl-c!
r.map(&amp;amp;:to_date)

# so use your `Enumerable` methods wisely
r.lazy.map(&amp;amp;:to_date).select { |d| d.mday &amp;gt; 25 }.take(5).to_a
=&amp;gt; [Fri, 26 Feb 2016,
Sat, 27 Feb 2016,
Sun, 28 Feb 2016,
Mon, 29 Feb 2016,
Sat, 26 Mar 2016]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s straightforward to convert recurrence options back to a hash.&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Every 10 minutes starting now
opts = Montrose::Recurrence.new(every: 10.minutes).to_h
=&amp;gt; {:every=&amp;gt;:minute, :interval=&amp;gt;10}

Montrose::Recurrence.new(opts).take(3)
=&amp;gt; [2016-02-03 19:06:07 -0500,
2016-02-03 19:16:07 -0500,
2016-02-03 19:26:07 -0500]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Accordingly, &lt;code&gt;Montrose::Recurrence&lt;/code&gt; implements &lt;code&gt;.dump&lt;/code&gt; and &lt;code&gt;.load&lt;/code&gt; so that you can use it with the &lt;code&gt;serialize&lt;/code&gt; feature of &lt;code&gt;ActiveRecord&lt;/code&gt; to back a recurrence by a database column in your Rails apps:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class EventSeries &amp;lt; ActiveRecord::Base
  serialize :recurrence, Montrose::Recurrence
end

es = EventSeries.new(recurrence: Montrose.daily.at(&amp;quot;12pm&amp;quot;))
es.save

es = EventSeries.last
es.recurrence
# =&amp;gt; #&amp;lt;Montrose::Recurrence:...&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This library is still in its early stages (version &lt;code&gt;0.2.1&lt;/code&gt; as of this writing) and aspects of the API are still in flux, such as the ability to configure default start and end times or combines multiple, distinct recurrences in a &lt;code&gt;Montrose::Schedule&lt;/code&gt;. &lt;code&gt;Montrose&lt;/code&gt; has one dependency - &lt;code&gt;ActiveSupport&lt;/code&gt; - for time calculations.&lt;/p&gt;

&lt;p&gt;There are &lt;a href="https://github.com/rossta/montrose/issues"&gt;plenty of missing features&lt;/a&gt;, including iCal serialization though Montrose already &lt;a href="https://github.com/rossta/montrose/blob/master/spec/rfc_spec.rb"&gt;supports most of the examples&lt;/a&gt; given by the iCal spec, &lt;a href="https://www.ietf.org/rfc/rfc2445.txt"&gt;rfc2445&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I still haven&amp;rsquo;t built that Edgar clone, but feel this is a good place from which to grow. As I said earlier, the &lt;code&gt;ice_cube&lt;/code&gt; gem is a mature library and already does much of what I&amp;rsquo;ve described here. Writing my own solution allowed me to think more deeply about the internal mechanisms for calculating recurrences and ultimately, once my curiosity was piqued, I couldn&amp;rsquo;t stop. If, you like what &lt;code&gt;Montrose&lt;/code&gt; has to offer and you&amp;rsquo;re feeling adventurous, try it out in your own application and send some feedback. Don&amp;rsquo;t hesitate to &lt;a href="https://github.com/rossta/montrose"&gt;fork the project&lt;/a&gt; and contribute.&lt;/p&gt;

&lt;p&gt;NYC.rb?&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# Second Tuesday of every month
r = Montrose.every(:month, day: { tuesday: [2] }, at: &amp;quot;7pm&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See you there.&lt;/p&gt;
</content>
  </entry>
</feed>
